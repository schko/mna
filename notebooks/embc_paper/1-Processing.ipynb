{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import mne\n",
    "import numpy as np\n",
    "import autoreject\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "from mna.sessions.eye_session import process_session_eye\n",
    "from mna.sessions.eeg_session import process_session_eeg\n",
    "from mna.sessions.motor_session import process_session_motor\n",
    "from mna.sessions.ecg_session import process_session_ecg\n",
    "from mna.utils.batch_feature_extraction import clean_up_adadrive_trials\n",
    "\n",
    "from mne.parallel import parallel_func\n",
    "from mne_features.univariate import compute_hjorth_mobility,compute_pow_freq_bands\n",
    "from mne.preprocessing import corrmap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from mna.utils.rnapp_data_format import read_all_lslpresets, return_metadata_from_name, event_data_from_data, read_event_data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# 2. Read a RN App, converted pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "lsl_dir = \"../mna/LSLPresets/\"\n",
    "output_dir = '../output/'\n",
    "pickle_dir = f'{output_dir}saved_files/pickle_files/'\n",
    "cvs_xlsx_dir = f'{output_dir}saved_files/cvs_xlsx_files/'\n",
    "\n",
    "timestamp_fixer_path = f\"{data_dir}annotated/fit_timestamp_adjuster.pkl\"\n",
    "\n",
    "if not os.path.isdir(output_dir): os.makedirs(output_dir)\n",
    "\n",
    "metadata_jsons = read_all_lslpresets(path_to_jsonfiles=lsl_dir)\n",
    "onlyfiles = [f for f in listdir(data_dir) if isfile(join(data_dir, f)) and '.pkl' in f]\n",
    "\n",
    "ts_fixer = pickle.load(open(timestamp_fixer_path, 'rb')) # features == 'processed_trial_duration',  'processed_trial_duration_1', 'lsl_timestamps'\n",
    "\n",
    "# all_dfs = pd.read_excel(\"output/all_results_cleaned.xlsx\")\n",
    "# all_dfs = clean_up_adadrive_trials(all_dfs)\n",
    "\n",
    "save_data_pkl = True # save data into pickle files\n",
    "save_ica_plts = True # save ICA components plots\n",
    "epoch_raw_eeg = True # epoching raw data\n",
    "motor_events = False\n",
    "seed = 64 # random state\n",
    "\n",
    "interrupted_sessions = [(13,1), (22,1)]\n",
    "# remove_sessions = [(13,1),(15,1),(22,1)]\n",
    "remove_sessions = [(13,1),(15,1),(22,1),(22,102)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_features(df, data_type = 'processed', features = 'all', label_source = 'Steering_Wheel_Degree_Encoded', \n",
    "                 cleaned_up = False):\n",
    "    \n",
    "    if data_type == 'processed':\n",
    "        first_electrode_column_name = \"Fp1_4-8_Hz_Power\"\n",
    "        last_electrode_column_name = \"O2_32-55_Hz_Sample_entropy\"\n",
    "        autoreject_column_name = \"autorejected\"\n",
    "    elif data_type == 'raw':\n",
    "        first_electrode_column_name = \"Fp1_4-8_Hz_Power_raw\"\n",
    "        last_electrode_column_name = \"O2_32-55_Hz_Sample_entropy_raw\"\n",
    "        autoreject_column_name = \"autorejected_raw\"\n",
    "        \n",
    "    first_electrode_idx = df.columns.get_loc(first_electrode_column_name)\n",
    "    last_electrode_idx = df.columns.get_loc(last_electrode_column_name)\n",
    "\n",
    "    # with autoreject\n",
    "    valid_trial = (df[label_source].notnull()) & (df[autoreject_column_name] == False)\n",
    "    \n",
    "    all_eeg_features = df.iloc[:,first_electrode_idx:last_electrode_idx+1] # all features in cleaned up data\n",
    "    \n",
    "    if features == 'all': \n",
    "        eeg_features = all_eeg_features\n",
    "    else:\n",
    "        features = \"|\".join(map(str,features))\n",
    "        eeg_features = all_eeg_features.loc[:, all_eeg_features.columns.str.contains(features)]\n",
    "    \n",
    "    if cleaned_up:\n",
    "        return np.asarray(eeg_features[valid_trial]), np.asarray(df[label_source][valid_trial])\n",
    "    else:\n",
    "        return eeg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_features(df, features = \"pupil\", label_source = 'Steering_Wheel_Degree_Encoded', cleaned_up = False):\n",
    "    pupil_diameter = ['Left Pupil Diameter','Right Pupil Diameter']\n",
    "    \n",
    "    if features == 'pupil':\n",
    "        # pupil_diameter.append(label_source)\n",
    "        eye_df = df[pupil_diameter]\n",
    "    else:\n",
    "        eye_feature = features\n",
    "        # eye_feature.append(label_source)\n",
    "        eye_df = df[eye_feature]\n",
    "        \n",
    "    if cleaned_up:\n",
    "        eye_df = eye_df.join(df[label_source]).dropna()\n",
    "        return np.asarray(eye_df.iloc[:,0:-1]), np.asarray(eye_df.iloc[:,-1])\n",
    "    else:\n",
    "        return eye_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecg_features(df, features = \"all\", label_source = 'Steering_Wheel_Degree_Encoded', cleaned_up = False):\n",
    "    ecg_feature_first = df.columns.get_loc(\"bpm\")\n",
    "    ecg_feature_last = df.columns.get_loc(\"breathingrate\")\n",
    "    \n",
    "    if features == 'all':\n",
    "        ecg_df = df.iloc[:,ecg_feature_first:ecg_feature_last-2]\n",
    "    else:\n",
    "        ecg_feature = features\n",
    "        # ecg_feature.append(label_source)\n",
    "        ecg_df = df[ecg_feature]\n",
    "    \n",
    "    if cleaned_up:\n",
    "        ecg_df = ecg_df.join(df[label_source]).dropna()\n",
    "        return np.asarray(ecg_df.iloc[:,0:-1]), np.asarray(ecg_df.iloc[:,-1])\n",
    "    else:\n",
    "        return ecg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimodal_features(df, label_source = 'Steering_Wheel_Degree_Encoded'):\n",
    "    \n",
    "    all_features_list = [eeg_features(df), eye_features(df), ecg_features(df), df[label_source]]\n",
    "    all_features_df = pd.concat(all_features_list, axis = 1).dropna()\n",
    "    \n",
    "    return np.asarray(all_features_df.iloc[:,0:-1]), np.asarray(all_features_df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_features(x_train, x_test):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train_norm = scaler.transform(x_train)\n",
    "    x_test_norm = scaler.transform(x_test)\n",
    "    \n",
    "    return x_train_norm, x_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalization(x_data, y_label, train_percentage=0.8):\n",
    "    \n",
    "    # Remove rows with invalid pupil diameter\n",
    "    if sum(sum(np.isnan(x_data))) > 0:\n",
    "        invalid_trial = np.argwhere(np.any(np.isnan(x_data) == True, axis=1))\n",
    "        x_data_corrected = np.delete(x_data, invalid_trial, axis=0)\n",
    "        y_label_corrected = np.delete(y_label, invalid_trial, axis=0)\n",
    "\n",
    "    else:\n",
    "        x_data_corrected = x_data\n",
    "        y_label_corrected = y_label\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data_corrected, y_label_corrected, \n",
    "                                                                            train_size = train_percentage, random_state=rs)\n",
    "    \n",
    "    norm_data = MinMaxScaler().fit(x_train)\n",
    "    x_train_norm = norm_data.transform(x_train)\n",
    "    x_test_norm = norm_data.transform(x_test)\n",
    "\n",
    "    return x_train_norm, x_test_norm, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modality_cv(x_modality, y_modality, n_folds = 10, classifier = 'logistic'):\n",
    "    \n",
    "    auc_list = np.empty((2, n_folds))\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = n_folds, random_state=rs, shuffle=True)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(x_modality, y_modality)):\n",
    "\n",
    "        x_train_norm, x_test_norm = norm_features(x_modality[train_index], x_modality[test_index])\n",
    "        train_auc, test_auc, coefs = trial_classification(x_train_norm, x_test_norm,\n",
    "                                                          y_modality[train_index], y_modality[test_index],\n",
    "                                                          classifier, plot_fig = False)\n",
    "        auc_list[0,i] = train_auc\n",
    "        auc_list[1,i] = test_auc\n",
    "    \n",
    "    return np.mean(auc_list, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(df, modality, true_val_col = 'Steering_Wheel_Degree', features_list = 'all'):\n",
    "    \n",
    "    if modality == \"EEG\":\n",
    "        x_modality, y_modality = eeg_features(df, features = features_list, label_source = true_val_col, \n",
    "                                              cleaned_up = True)\n",
    "    if modality == \"Eye\":\n",
    "        if features_list == 'all':\n",
    "            features_list = [\"Left Pupil Diameter\", \"Right Pupil Diameter\",\n",
    "                            \"Left Evoked Pupil Diameter\", \"Right Evoked Pupil Diameter\"]\n",
    "        x_modality, y_modality = eye_features(df, features = features_list, label_source = true_val_col, \n",
    "                                              cleaned_up = True)\n",
    "    if modality == \"ECG\":\n",
    "        x_modality, y_modality = ecg_features(df, features = features_list, label_source = true_val_col, \n",
    "                                              cleaned_up = True)\n",
    "    if modality == \"All\":\n",
    "        x_modality, y_modality = multimodal_features(df, label_source = true_val_col)\n",
    "        \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_modality, y_modality, test_size=0.3, random_state=rs)\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = regr.predict(X_test)\n",
    "    modality_rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    \n",
    "    return y_test, y_pred, modality_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 3. Process, Save, and Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Process file function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_files(template_ica = None, each_file):\n",
    "\n",
    "    input_path = data_dir + each_file\n",
    "\n",
    "    sbj_id = each_file[each_file.find('Sbj_')+4:each_file.find('-Ssn')]\n",
    "    ssn_no = each_file[each_file.find('Ssn_')+4:each_file.find('.dats')]\n",
    "\n",
    "    if len(sbj_id) < 2: sbj = \"sbj0\"+sbj_id\n",
    "    else: sbj = \"sbj\"+sbj_id\n",
    "    if len(ssn_no) < 2: ssn = \"ssn0\"+ssn_no\n",
    "    else: ssn = \"ssn\"+ssn_no\n",
    "\n",
    "    if template_ica: ref_ica = template_ica\n",
    "    else: ref_ica = None\n",
    "\n",
    "    with open(input_path, 'rb') as handle:\n",
    "        rns_data = pickle.load(handle)\n",
    "\n",
    "    ## Add metadata to data\n",
    "    for key in rns_data.keys():\n",
    "        rns_data[key].append(return_metadata_from_name(key, metadata_jsons))\n",
    "\n",
    "    event_df = read_event_data(rns_data) # typically only 15_1 and 22_1 will be used here, change below too\n",
    "\n",
    "    if event_df.empty:\n",
    "        return None\n",
    "\n",
    "    event_df = event_df[event_df.block_condition == 'voice']\n",
    "    event_df['trial_damage'] = event_df.damage.diff().fillna(0)\n",
    "    event_df['trial_duration'] = event_df.trial_end_time - event_df.trial_start_time\n",
    "\n",
    "    percent_missing = event_df.notnull().sum() / len(event_df)\n",
    "    summary_statistics = {}\n",
    "    summary_statistics['voice_success_rate'] = percent_missing['spoken_difficulty']\n",
    "    event_df['spoken_difficulty'] = event_df['spoken_difficulty'].fillna(\"unknown\")\n",
    "    event_df['spoken_difficulty_encoded'] = event_df.spoken_difficulty.replace(to_replace=['easy', 'hard', 'unknown'],\n",
    "                                                                          value=[1, 2, 0])\n",
    "\n",
    "    # ecg\n",
    "    post_processed_event_df = process_session_ecg(rns_data, event_df,plot_frequency=20,plot_ecg_snippet=40)\n",
    "\n",
    "    # eye\n",
    "    if 'Unity_ViveSREyeTracking' in rns_data:\n",
    "        post_processed_event_df = process_session_eye(rns_data, post_processed_event_df,detect_blink=True,\n",
    "                                                      pretrial_period=0, posttrial_period=0, plot_frequency=20, \n",
    "                                                      plot_eye_snippet=40, classifiers=['NSLR'])\n",
    "\n",
    "    # eeg\n",
    "    post_processed_event_df, epochs, events, info, reject_log, ica, eog_idx= process_session_eeg(rns_data, post_processed_event_df,\n",
    "                                run_autoreject=True, run_ica=True, save_raw_eeg = True, sbj_session = sbj+ssn, \n",
    "                                template_ica = ref_ica, analyze_pre_ica = True)\n",
    "\n",
    "    # motor\n",
    "    post_processed_event_df, turns_df = process_session_motor(rns_data, post_processed_event_df, motor_channel='Unity_MotorInput',\n",
    "                                                plot_motor_result = True, plot_motor_snippet = 30, plot_frequency = 10)\n",
    "\n",
    "    # save data for later use\n",
    "    if save_data_pkl:\n",
    "\n",
    "        with open(f'{pickle_dir}all_events.pickle', 'wb') as handle_events:\n",
    "            pickle.dump(events, handle_events, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(f'{pickle_dir}ica_epochs.pickle', 'wb') as handle_ica_eps:\n",
    "            pickle.dump(epochs, handle_ica_eps, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(f'{pickle_dir}ica.pickle', 'wb') as handle_ica:\n",
    "            pickle.dump(ica, handle_ica, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(f'{pickle_dir}eog_comp.pickle', 'wb') as handle_eog:\n",
    "            pickle.dump(eog_idx, handle_eog, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    return post_processed_event_df, events, epochs, ica, eog_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Multiprocessing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process data for first participant and identify components need to be removed - template ica\n",
    "results = []\n",
    "result = process_file(each_file = onlyfiles[0])\n",
    "template_ica = result[3]\n",
    "\n",
    "# Multiprocessing \n",
    "cpu_no = 4\n",
    "multi_process_files = False\n",
    "\n",
    "if multi_process_files:\n",
    "    with Pool(cpu_no) as p:\n",
    "        results = p.map(partial(process_file, template_ica), onlyfiles)\n",
    "else:\n",
    "    for only in onlyfiles[1:]:\n",
    "        result = process_file(template_ica, onlyfile)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            \n",
    "all_dfs = pd.concat([r[0] for r in results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe\n",
    "\n",
    "all_dfs.to_csv(f\"{cvs_xlsx_dir}all_results.csv\")\n",
    "all_dfs.to_excel(f\"{cvs_xlsx_dir}all_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Processing Raw EEG Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load raw eeg.fif file and epoch raw eeg\n",
    "\n",
    "if epoch_raw_eeg:\n",
    "\n",
    "    with open(f'{pickle_dir}all_events.pickle', 'rb') as handle:\n",
    "        all_events = pickle.load(handle)\n",
    "\n",
    "    raw_eeg_dir = f'{output_dir}saved_files/raw_eeg/'\n",
    "    event_dict = dict(easy=1, hard=2)\n",
    "\n",
    "    raw_eeg_dict = {}\n",
    "    raw_epochs_dict = {}\n",
    "\n",
    "    for sbj_ssn in list(all_events.keys()):\n",
    "\n",
    "        each_raw_eeg = sbj_ssn + '_eeg_filt_raw.fif'\n",
    "        raw_eeg_path = raw_eeg_dir+each_raw_eeg\n",
    "        raw_eeg = mne.io.read_raw_fif(raw_eeg_path, preload=True)\n",
    "        raw_eeg_dict[sbj_ssn] = raw_eeg\n",
    "\n",
    "        epochs_raw = mne.Epochs(raw_eeg, all_events[sbj_ssn], event_id=event_dict, baseline = (None, 0), tmin= -.2, tmax=3, preload=True, on_missing='warn')\n",
    "\n",
    "        autoreject_epochs = 20\n",
    "        run_autoreject = True\n",
    "\n",
    "        if len(epochs_raw) < 10: # we need at least 10 epochs to run autoreject for cross validation\n",
    "            # bad_epochs_raw = pd.Series(np.full(len(event_df),np.NAN), index=event_df.index, name='autorejected')\n",
    "            # event_df = event_df.join(bad_epochs)\n",
    "            reject_log = None\n",
    "        elif run_autoreject:\n",
    "            ar_raw = autoreject.AutoReject(random_state=rs,n_jobs=1, verbose=False)\n",
    "            ar_raw.fit(epochs_raw[:autoreject_epochs])  # fit on a few epochs to save time\n",
    "            epochs_ar, reject_log = ar_raw.transform(epochs_raw, return_log=True)\n",
    "            # bad_epochs = pd.Series(reject_log.bad_epochs, index=event_recognized_df.index, dtype=bool, name='autorejected')\n",
    "            # event_df = event_df.join(bad_epochs_raw) # creates nan if not processed at all\n",
    "            epochs_raw = epochs_ar\n",
    "\n",
    "        raw_epochs_dict[sbj_ssn] = epochs_raw\n",
    "\n",
    "    with open(f'{pickle_dir}raw_epochs.pickle', 'wb') as handle_raw_eps:\n",
    "        pickle.dump(raw_epochs_dict, handle_raw_eps, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f'{pickle_dir}raw_eeg.pickle', 'wb') as handle_raw_eeg:\n",
    "        pickle.dump(raw_eeg_dict, handle_raw_eeg, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_dfs = pd.read_csv(\"../output/saved_files/corrected_voice_timestamp/all_results.csv\")\n",
    "\n",
    "# open saved pickle files\n",
    "with open(f'{pickle_dir}ica_epochs.pickle', 'rb') as handle:\n",
    "    all_proc_epochs = pickle.load(handle)\n",
    "with open(f'{pickle_dir}ica.pickle', 'rb') as handle:\n",
    "    all_ica = pickle.load(handle)\n",
    "with open(f'{pickle_dir}eog_comp.pickle', 'rb') as handle:\n",
    "    all_eog_comps = pickle.load(handle)\n",
    "with open(f'{pickle_dir}raw_epochs.pickle', 'rb') as handle:\n",
    "    all_raw_epochs = pickle.load(handle)\n",
    "\n",
    "# save ICA components plot\n",
    "if save_ica_plts:\n",
    "    ica_comp_dir = \"../output/plots/ica_comps/\"\n",
    "    if not os.path.isdir(ica_comp_dir): os.makedirs(ica_comp_dir)\n",
    "\n",
    "    for sbj_ssn in list(all_ica.keys()):\n",
    "        \n",
    "        all_ica[sbj_ssn].plot_components(picks = list(range(0,20)), title=sbj_ssn+\"_ICA_Components\", show=False)\n",
    "\n",
    "        plt.savefig(f\"{ica_comp_dir}{sbj_ssn}_ica_comps.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed component for all sessions\n",
    "\n",
    "show_removed_comp = False\n",
    "\n",
    "if show_removed_comp:\n",
    "    for sbj in all_ica.keys():\n",
    "        if all_eog_comps[sbj] != []:\n",
    "\n",
    "            all_ica[sbj].plot_components(picks = all_eog_comps[sbj], title=sbj, show=False)\n",
    "\n",
    "            plt.savefig(f\"{output_dir}/plots/Removed_Components_Corrmap/{sbj}_removed_components.png\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "# all_eog_comps.values()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3 (default, Oct 31 2022, 14:04:00) \n[GCC 8.3.0]"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
