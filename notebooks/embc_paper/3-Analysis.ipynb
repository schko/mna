{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('../..')\n",
    "\n",
    "import pandas as pd\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from mna.utils.rnapp_data_format import read_all_lslpresets, return_metadata_from_name, event_data_from_data, read_event_data\n",
    "from mna.utils.batch_feature_extraction import clean_up_adadrive_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 2. Feature Extraction and Predction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.1 Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_features(df, data_type = 'processed', features = 'all', ground_truth = 'Steering_Wheel_Degree_Encoded', \n",
    "                 cleaned_up = False):\n",
    "    \n",
    "    if data_type == 'processed':\n",
    "        first_electrode_column_name = \"Fp1_4-8_Hz_Power\"\n",
    "        last_electrode_column_name = \"O2_32-55_Hz_Sample_entropy\"\n",
    "        autoreject_column_name = \"autorejected\"\n",
    "    elif data_type == 'raw':\n",
    "        first_electrode_column_name = \"Fp1_4-8_Hz_Power_raw\"\n",
    "        last_electrode_column_name = \"O2_32-55_Hz_Sample_entropy_raw\"\n",
    "        autoreject_column_name = \"autorejected_raw\"\n",
    "        \n",
    "    first_electrode_idx = df.columns.get_loc(first_electrode_column_name)\n",
    "    last_electrode_idx = df.columns.get_loc(last_electrode_column_name)\n",
    "\n",
    "    # with autoreject\n",
    "    valid_trial = (df[ground_truth].notnull()) & (df[autoreject_column_name] == False)\n",
    "    \n",
    "    all_eeg_features = df.iloc[:,first_electrode_idx:last_electrode_idx+1] # all features in cleaned up data\n",
    "    \n",
    "    if features == 'all': \n",
    "        eeg_features = all_eeg_features\n",
    "    else:\n",
    "        features = \"|\".join(map(str,features))\n",
    "        eeg_features = all_eeg_features.loc[:, all_eeg_features.columns.str.contains(features)]\n",
    "    \n",
    "    if cleaned_up:\n",
    "        return np.asarray(eeg_features[valid_trial]), np.asarray(df[ground_truth][valid_trial])\n",
    "    else:\n",
    "        return eeg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_features(df, features = 'all', ground_truth = 'Steering_Wheel_Degree_Encoded', cleaned_up = False):\n",
    "    \n",
    "    if features == 'all':\n",
    "        eye_df = df['Left Pupil Diameter', 'NSLR_count_Fixation', 'NSLR_count_Saccade', 'NSLR_mean_duration_Fixation', \n",
    "                    'NSLR_mean_duration_Saccade', 'NSLR_first_onset_Fixation', 'NSLR_first_onset_Saccade']\n",
    "    else:\n",
    "        eye_feature = features\n",
    "        eye_df = df[eye_feature]\n",
    "        \n",
    "    if cleaned_up:\n",
    "        eye_df = eye_df.join(df[ground_truth]).dropna()\n",
    "        return np.asarray(eye_df.iloc[:,0:-1]), np.asarray(eye_df.iloc[:,-1])\n",
    "    else:\n",
    "        return eye_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecg_features(df, features = \"all\", ground_truth = 'Steering_Wheel_Degree_Encoded', cleaned_up = False):\n",
    "    ecg_feature_first = df.columns.get_loc(\"bpm\")\n",
    "    ecg_feature_last = df.columns.get_loc(\"breathingrate\")\n",
    "    \n",
    "    if features == 'all':\n",
    "        ecg_df = df.iloc[:,ecg_feature_first:ecg_feature_last-2]\n",
    "    else:\n",
    "        ecg_feature = features\n",
    "        ecg_df = df[ecg_feature]\n",
    "    \n",
    "    if cleaned_up:\n",
    "        ecg_df = ecg_df.join(df[ground_truth]).dropna()\n",
    "        return np.asarray(ecg_df.iloc[:,0:-1]), np.asarray(ecg_df.iloc[:,-1])\n",
    "    else:\n",
    "        return ecg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimodal_features(df, features = \"all\", ground_truth = 'Steering_Wheel_Degree_Encoded'):\n",
    "    \n",
    "    if features == \"all\":\n",
    "        all_features_list = [eeg_features(df), eye_features(df), ecg_features(df), df[ground_truth]]\n",
    "        all_features_df = pd.concat(all_features_list, axis = 1).dropna()\n",
    "    else:\n",
    "        all_features_df = df[features].join(df[ground_truth]).dropna()\n",
    "    \n",
    "    return np.asarray(all_features_df.iloc[:,0:-1]), np.asarray(all_features_df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.2 Features Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_features(x_train, x_test):\n",
    "    \n",
    "    scaler = MinMaxScaler().fit(x_train)\n",
    "    x_train_norm = scaler.transform(x_train)\n",
    "    x_test_norm = scaler.transform(x_test)\n",
    "    \n",
    "    return x_train_norm, x_test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3 Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_prediction(train_data, test_data, train_true, test_true, prediction_type = \"classification\", \n",
    "                     seed = 42, save_plots = False, plot_fig = True):\n",
    "\n",
    "    if prediction_type == \"regression\":\n",
    "        random_forest = RandomForestRegressor(random_state = seed).fit(train_data, train_true)\n",
    "        mse = mean_squared_error(test_true, random_forest.predict(test_data), squared=True)\n",
    "        rmse = mean_squared_error(test_true, random_forest.predict(test_data), squared=False)\n",
    "        \n",
    "    if prediction_type == \"classification\":\n",
    "        random_forest = RandomForestClassifier(random_state = seed, \n",
    "                                               class_weight = 'balanced_subsample').fit(train_data, train_true)\n",
    "        \n",
    "        score_train = random_forest.predict_proba(train_data)[:,1]\n",
    "        score_test = random_forest.predict_proba(test_data)[:,1]\n",
    "        \n",
    "        train_pred = random_forest.predict(train_data)\n",
    "        test_pred = random_forest.predict(test_data)\n",
    "\n",
    "        fpr_train, tpr_train, thresholds_train = metrics.roc_curve(train_true-1, score_train)\n",
    "        auc_train = metrics.roc_auc_score (train_true-1, score_train)\n",
    "\n",
    "        fpr_test, tpr_test, thresholds_test = metrics.roc_curve(test_true-1, score_test)\n",
    "        auc_test = metrics.roc_auc_score (test_true-1, score_test)\n",
    "\n",
    "        train_acc = metrics.accuracy_score(train_true,train_pred)\n",
    "        test_acc = metrics.accuracy_score(test_true,test_pred) \n",
    "        \n",
    "    importance = random_forest.feature_importances_ \n",
    "\n",
    "    if plot_fig:\n",
    "        # Features Importance\n",
    "        fig_importance = plt.figure(figsize = [10 ,3])\n",
    "        axe = fig_importance.add_subplot(1,1,1)\n",
    "\n",
    "        markerline, stemline, baseline = axe.stem([x for x in range(len(importance))], importance, \n",
    "                                                  linefmt='k-',markerfmt='ko',basefmt='k.')\n",
    "        plt.setp(stemline, linewidth = 1)\n",
    "        plt.setp(markerline, markersize = 1)\n",
    "        axe.set_xlabel(\"Feature\")\n",
    "        axe.set_ylabel(\"Importance\")\n",
    "        axe.set_title(\"Coefficient for Each Features\")\n",
    "        if save_plots:\n",
    "            plt.savefig(f\"../output/classification_result/feature_importance.png\")\n",
    "        \n",
    "        if prediction_type == \"classification\":\n",
    "            # ROC Curve\n",
    "            sns.set(font_scale=2)\n",
    "            plt.style.use('seaborn-white')\n",
    "            fig = plt.figure(figsize = [25,7])\n",
    "\n",
    "            axe = fig.add_subplot(1,2,1)\n",
    "            axe.plot(fpr_train,tpr_train)\n",
    "            axe.set_xlabel(\"False Positive Rate\")\n",
    "            axe.set_ylabel(\"True Positive Rate\")\n",
    "            axe.set_title(\"Training ROC Curve\")\n",
    "            axe.text(0.6,0.2,\"AUC = {:.2f}\".format(auc_train))\n",
    "\n",
    "            axe = fig.add_subplot(1,2,2)\n",
    "            axe.plot(fpr_test,tpr_test)\n",
    "            axe.set_xlabel(\"False Positive Rate\")\n",
    "            axe.set_ylabel(\"True Positive Rate\")\n",
    "            axe.set_title(\"Testing ROC Curve\")\n",
    "            axe.text(0.6,0.2,\"AUC = {:.2f}\".format(auc_test))\n",
    "\n",
    "            if save_plots:\n",
    "                plt.savefig(f\"../output/classification_result/training_testing_ROC_Curve.png\", dpi=300)\n",
    "\n",
    "            # Confusion Matrix\n",
    "            fig_cnf = plt.figure(figsize = [20, 5])\n",
    "            ax1 = fig_cnf.add_subplot(1,2,1)\n",
    "            ax2 = fig_cnf.add_subplot(1,2,2)\n",
    "\n",
    "            cnf_matrix_train = metrics.confusion_matrix(train_true, train_pred)\n",
    "            cnf_matrix_test = metrics.confusion_matrix(test_true, test_pred)\n",
    "\n",
    "            sns.heatmap(cnf_matrix_train, fmt = 'g', annot = True, xticklabels = ['Easy','Hard'], yticklabels = ['Easy','Hard'],ax=ax1)\n",
    "            ax1.set_title(\"Training Confusion Matrix\")\n",
    "            sns.heatmap(cnf_matrix_test, fmt = 'g', annot = True, xticklabels = ['Easy','Hard'], yticklabels = ['Easy','Hard'],ax=ax2)\n",
    "            ax2.set_title(\"Testing Confusion Matrix\")\n",
    "\n",
    "            if save_plots:\n",
    "                plt.savefig(f\"../output/classification_result/training_testing_confusion_matrix.png\", dpi=300)\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    if prediction_type == 'classification':\n",
    "        return auc_train, auc_test, importance\n",
    "    if prediction_type == 'regression':\n",
    "        return mse, rmse, importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.4 Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cv(x_modality, y_modality, n_folds = 10, model_type = 'classification', seed = 42):\n",
    "    \n",
    "    all_model_metrics = np.empty((2, n_folds))\n",
    "    model_importance = np.empty((n_folds, x_modality.shape[1]))\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = n_folds, random_state = seed, shuffle=True)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(x_modality, y_modality)):\n",
    "\n",
    "        x_train_norm, x_test_norm = norm_features(x_modality[train_index], x_modality[test_index])\n",
    "        model_metric_1, model_metric_2, coefs = trial_prediction(x_train_norm, x_test_norm, \n",
    "                                                      y_modality[train_index], y_modality[test_index],\n",
    "                                                      prediction_type = model_type, plot_fig = False)\n",
    "        all_model_metrics[0,i] = model_metric_1\n",
    "        all_model_metrics[1,i] = model_metric_2\n",
    "        model_importance[i,:] = coefs\n",
    "    \n",
    "    return np.mean(all_model_metrics, axis = 1), model_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Motor Events Trial Level Classfication/Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.1 Dataframe Processing and Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_output_dir = (f\"../../output/batch_analysis/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "def str_list_to_list(lst):\n",
    "    str_single_space = re.sub(\"\\s+\", \" \", lst.strip())\n",
    "    str_no_brackets = re.sub(\"[\\[\\]]\", \"\", lst)\n",
    "    return [float(n) for n in str_no_brackets.split()]\n",
    "\n",
    "# loop over the list of csv files\n",
    "def read_motor_csvs():\n",
    "    csv_files = glob.glob(os.path.join(motor_output_dir, \"ppid*_motor.csv\"))\n",
    "    all_dfs = None\n",
    "    for f in csv_files:\n",
    "        # read the csv file and add column for labels\n",
    "        temp_df = pd.read_csv(f)\n",
    "\n",
    "        all_steer_events = temp_df.copy()['post_steer_event_raw']\n",
    "        all_steer_events_finalized = all_steer_events.apply(str_list_to_list)\n",
    "\n",
    "        norm_pos = lambda wheel_pos: np.asarray(wheel_pos)/np.asarray(wheel_pos[0])\n",
    "        final_pos = lambda final_wheel_pos: np.asarray(final_wheel_pos[-1])-np.asarray(final_wheel_pos[0])\n",
    "\n",
    "        norm_pos_df = all_steer_events_finalized.apply(norm_pos)\n",
    "\n",
    "        temp_df['steering_wheel_degree'] = abs(all_steer_events_finalized.apply(final_pos))\n",
    "        temp_df['steering_wheel_degree_categorical'] = pd.qcut(temp_df['steering_wheel_degree'], 2, labels=[\"Low\", \"High\"]) #2=High, 1 =Low\n",
    "        temp_df['steering_wheel_degree_encoded'] = temp_df.Steer_Wheel_Degree_Categorical.replace({'High': 2, 'Low': 1})\n",
    "        \n",
    "        if not type(all_dfs)==pd.core.frame.DataFrame:\n",
    "            all_dfs = temp_df\n",
    "        else:\n",
    "            all_dfs = pd.concat([all_dfs, temp_df], ignore_index=True)\n",
    "            \n",
    "    all_dfs = all_dfs[all_dfs.columns.drop(list(all_dfs.filter(regex='Unnamed')))]\n",
    "    \n",
    "    return all_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs_final = read_motor_csvs()\n",
    "motor_all_dfs = all_dfs_final.copy()\n",
    "\n",
    "remove_sessions = [(13,1),(15,1),(22,1),(22,102)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_all_dfs['sub_sess'] = motor_all_dfs.ppid.astype(str) + \"_\" + motor_all_dfs.session.astype(str)\n",
    "motor_all_dfs = motor_all_dfs.loc[~motor_all_dfs.sub_sess.isin([f\"{es[0]}.0_{es[1]}.0\" for es in remove_sessions])]\n",
    "\n",
    "motor_all_dfs['mean_steering_wheel_degree'] = motor_all_dfs.Steering_Wheel_Degree.mean()\n",
    "\n",
    "motor_all_dfs['pupil_bin'] = motor_all_dfs.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=['low', 'high']))\n",
    "motor_all_dfs['pupil_bin_encoded'] = motor_all_dfs.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=[1, 2]))\n",
    "\n",
    "motor_all_dfs = clean_up_adadrive_trials(motor_all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# luminance effect removal\n",
    "\n",
    "pupil_df = pd.read_csv(f\"../output/pupil_exposure/participant_level_exposure_fits.csv\")\n",
    "motor_all_dfs['Raw Left Pupil Diameter'] = motor_all_dfs['Left Pupil Diameter']\n",
    "p_val_criteria = 0.05\n",
    "\n",
    "for index, row in motor_all_dfs.reset_index(drop=True).iloc[1:].iterrows():\n",
    "    last_ppid = motor_all_dfs.iloc[index-1].ppid\n",
    "    last_session = motor_all_dfs.iloc[index-1].session\n",
    "    last_trial = motor_all_dfs.iloc[index-1].trial\n",
    "    last_opacity = motor_all_dfs.iloc[index-1].density\n",
    "    if ((row.ppid == last_ppid) & (row.session == last_session) & (row.trial == last_trial+1)): # if continuous\n",
    "        # if there is a significant effect of opacity on pupil\n",
    "        if pupil_df.loc[pupil_df['sub']==last_ppid,'p_opacities'].values < p_val_criteria:\n",
    "            this_opacity = row.density\n",
    "            this_pupil_diameter = row['Left Pupil Diameter']\n",
    "            weight = pupil_df.loc[pupil_df['sub']==last_ppid,'w_opacities']\n",
    "            adjustment = (this_opacity-last_opacity)*weight\n",
    "            motor_all_dfs.iloc[index,motor_all_dfs.columns.get_loc('Left Pupil Diameter')] -= adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=motor_all_dfs, x=\"steering_wheel_degree\")\n",
    "# plt.savefig(f\"../output/plots/steering_wheel_turned_deg.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motor_all_dfs.to_csv(f\"../output/batch_analysis/motor_df_label.csv\")\n",
    "# motor_all_dfs.to_excel(f\"../output/batch_analysis/motor_df_label.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3.2 Classification - Voice, Pupil-linked Arousal, Steering Wheel Turned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_func(motor_dfs, predictions = 'spoken_difficulty_encoded', pred_type = 'classification'):\n",
    "    \n",
    "    predictors_1 = ['density', 'Left Pupil Diameter', \n",
    "                  'FC3_4-8_Hz_Power', 'FC3_8-15_Hz_Power', 'FC3_15-32_Hz_Power', 'FC3_32-55_Hz_Power', \n",
    "                  'FC1_4-8_Hz_Power', 'FC1_8-15_Hz_Power', 'FC1_15-32_Hz_Power', 'FC1_32-55_Hz_Power', \n",
    "                  'FCz_4-8_Hz_Power', 'FCz_8-15_Hz_Power', 'FCz_15-32_Hz_Power', 'FCz_32-55_Hz_Power',\n",
    "                  'FC2_4-8_Hz_Power', 'FC2_8-15_Hz_Power', 'FC2_15-32_Hz_Power', 'FC2_32-55_Hz_Power', \n",
    "                  'FC4_4-8_Hz_Power', 'FC4_8-15_Hz_Power', 'FC4_15-32_Hz_Power', 'FC4_32-55_Hz_Power']\n",
    "\n",
    "    predictors_2 = ['density', 'Left Pupil Diameter', \n",
    "                  'NSLR_count_Fixation', 'NSLR_count_Saccade', \n",
    "                  'NSLR_mean_duration_Fixation', 'NSLR_mean_duration_Saccade', \n",
    "                  'NSLR_first_onset_Fixation', 'NSLR_first_onset_Saccade', \n",
    "                  'bpm', 'sdnn', 'rmssd', 'pnn50']\n",
    "    \n",
    "    motor_dfs_filtered = motor_dfs.copy()\n",
    "    motor_dfs_filtered = motor_dfs_filtered[motor_dfs_filtered[predictions] != 0]\n",
    "    \n",
    "    if predictions == 'pupil_bin_encoded':\n",
    "        predictors_1.remove('Left Pupil Diameter')\n",
    "        predictors_2.remove('Left Pupil Diameter')\n",
    "    \n",
    "    x_pupil_eeg, y_pupil_eeg = multimodal_features(motor_dfs_filtered, features = predictors_1, \n",
    "                                                   ground_truth = predictions)\n",
    "    x_eye_ecg, y_eye_ecg = multimodal_features(motor_dfs_filtered, features = predictors_2, \n",
    "                                               ground_truth = predictions)\n",
    "\n",
    "    modalities_dict = {\"pupil_eeg\": (x_pupil_eeg, y_pupil_eeg),\n",
    "                       \"eye_ecg\": (x_eye_ecg, y_eye_ecg)}\n",
    "                                                   \n",
    "    modalities_metric = {}\n",
    "    features_coefs = {}\n",
    "\n",
    "    for modalities in list(modalities_dict.keys()):\n",
    "\n",
    "        metric, coef = model_cv(modalities_dict[modalities][0], modalities_dict[modalities][1], \n",
    "                             model_type = pred_type)\n",
    "        modalities_metric[modality] = metric\n",
    "        modalities_coefs[modality] = coef\n",
    "    if pred_type == 'classification':\n",
    "        modalities_metric = pd.DataFrame(modalities_auc, index = ['Train AUC', 'Test AUC'])\n",
    "    elif pred_type == 'regression':\n",
    "        modalities_metric = pd.DataFrame(modalities_auc, index = ['MSE', 'RMSE'])\n",
    "\n",
    "    return modalities_metric, modalities_coefs, [predictors_1, predictors_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_df_voice, modalities_coefs_voice, features_voice = pred_func(motor_all_dfs, predictions = 'spoken_difficulty_encoded')\n",
    "auc_df_arousal, modalities_coefs_arousal, features_arousal = pred_func(motor_all_dfs, predictions = 'pupil_bin_encoded')\n",
    "auc_df_wheel_deg, modalities_coefs_wheel_deg, features_wheel_deg = pred_func(motor_all_dfs, predictions = 'steering_wheel_degree_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_importance_plot(pred_importance_avg, pred_importance_std, pred_feature_list)\n",
    "    importance_fig = plt.figure(figsize = [10 ,3])\n",
    "    axe = importance_fig.add_subplot(1,1,1)\n",
    "    \n",
    "    features_no = np.arange(len(clf_importance_avg))\n",
    "\n",
    "    markerline, stemline, baseline = axe.bar(features_no, pred_importance_avg, yerr=pred_importance_std, \n",
    "                                             align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    axe.set_xticks(features_no)\n",
    "    axe.set_xticklabels(pred_feature_list)\n",
    "    axe.set_ylabel(\"Importance\")\n",
    "    axe.set_title(\"Importance for Each Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_voice_clf_avg = np.mean(modalities_coefs_voice[0], axis = 0)\n",
    "importance_voice_clf_std = np.std(modalities_coefs_voice[0], axis = 0)\n",
    "feature_list_voice_clf = features_voice[0]\n",
    "\n",
    "cv_importance_plot(importance_voice_clf_avg, importance_voice_clf_std, feature_list_voice_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.3 Motor Event Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mean = mean_squared_error(motor_all_dfs['steering_wheel_degree'], \n",
    "                               motor_all_dfs['mean_steering_wheel_degree'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_rmse, motor_reg_coefs, motor_reg_features = pred_func(motor_all_dfs, predictions = 'steering_wheel_degree', \n",
    "                                   pred_type = 'regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_motor_pred_avg = np.mean(motor_reg_coefs[0], axis = 0)\n",
    "importance_motor_pred_std = np.std(motor_reg_coefs[0], axis = 0)\n",
    "feature_list_motor_reg = motor_reg_features[0]\n",
    "\n",
    "cv_importance_plot(importance_motor_pred_avg, importance_motor_pred_std, feature_list_motor_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# results_clf_reg.to_csv(f'../output/saved_files/all_modality_rmse_auc.csv')\n",
    "results_clf_reg.to_excel(f'../output/saved_files/all_modality_rmse_auc.xlsx')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
  },
  "kernelspec": {
   "display_name": "mna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "vscode": {
   "interpreter": {
    "hash": "967869b3d3e599d39c4e482f6852385da2dcc34e629cb6c89bbd952eba61abed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
