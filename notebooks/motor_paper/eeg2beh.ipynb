{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96671aa",
   "metadata": {},
   "source": [
    "# Analyze sessions in batch from Phase 1 of AdaDrive (work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261d0746",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# setting path\n",
    "sys.path.append('..')\n",
    "import mne\n",
    "import matplotlib\n",
    "from mna.utils.rnapp_data_format import read_all_lslpresets, return_metadata_from_name, event_data_from_data\n",
    "import pickle, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from scipy.io import savemat\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from mna.utils.rnapp_data_format import read_all_lslpresets, return_metadata_from_name, event_data_from_data\n",
    "import pickle\n",
    "from statannotations.Annotator import Annotator\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "import mne\n",
    "import glob \n",
    "import random\n",
    "import re\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels as sm\n",
    "from scipy.stats import spearmanr\n",
    "# matplotlib.use('Qt5Agg')\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "from mna.utils.rnapp_data_format import read_all_files\n",
    "# 1. Read a RN App, converted pkl file, and create the metadata and data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c13166b",
   "metadata": {},
   "source": [
    "# Aux functions, read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa8d3fc-4b04-4d3a-ad36-8179b5eac0c8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop over the list of csv files\n",
    "def read_motor_csvs():\n",
    "    csv_files = glob.glob(os.path.join(output_dir, \"ppid*_motor.csv\"))\n",
    "    all_dfs = None\n",
    "    for f in csv_files:\n",
    "        # read the csv file\n",
    "        if not type(all_dfs)==pd.core.frame.DataFrame:\n",
    "            all_dfs = pd.read_csv(f)\n",
    "        else:\n",
    "            all_dfs = pd.concat([all_dfs, pd.read_csv(f)], ignore_index=True)\n",
    "    all_dfs = all_dfs[all_dfs.columns.drop(list(all_dfs.filter(regex='Unnamed')))]\n",
    "    return all_dfs\n",
    "\n",
    "def get_motor_epochs():\n",
    "    epochs_files = glob.glob(os.path.join(output_dir, \"**/*ica_epochs.pickle\"), recursive=True)\n",
    "    motor_epochs = []\n",
    "    for each_file in epochs_files:\n",
    "        motor_epochs.append(pickle.load(open(each_file, 'rb')))\n",
    "    motor_epochs = mne.concatenate_epochs(motor_epochs)\n",
    "    for col in ['ppid','session','block','number_in_block','trial']:\n",
    "        motor_epochs.metadata[col] = motor_epochs.metadata[col].astype(int)\n",
    "    return motor_epochs\n",
    "\n",
    "def get_motor_intensity_info(input_df):\n",
    "    \n",
    "    def str_list_to_list(lst):\n",
    "        str_single_space = re.sub(\"\\s+\", \" \", lst.strip())\n",
    "        str_no_brackets = re.sub(\"[\\[\\]]\", \"\", lst)\n",
    "        return [float(n) for n in str_no_brackets.split()]\n",
    "    \n",
    "    try:\n",
    "        all_steer_events = input_df['post_steer_event_raw']\n",
    "        all_steer_events_finalized = all_steer_events.apply(str_list_to_list)\n",
    "    except:\n",
    "        all_steer_events_finalized = input_df['post_steer_event_raw']\n",
    "    norm_pos = lambda wheel_pos: np.asarray(wheel_pos)/np.asarray(wheel_pos[0])\n",
    "    final_pos = lambda final_wheel_pos: np.asarray(final_wheel_pos[-1])-np.asarray(final_wheel_pos[0])\n",
    "\n",
    "    norm_pos_df = all_steer_events_finalized.apply(norm_pos)\n",
    "    final_pos_df = abs(all_steer_events_finalized.apply(final_pos))\n",
    "    input_df[\"Steer_Wheel_Degree\"] = abs(all_steer_events_finalized.apply(final_pos))\n",
    "    all_dfs = []\n",
    "    for sub in input_df.ppid.unique():\n",
    "        sub_df = input_df[input_df.ppid==sub]\n",
    "        sub_df[\"Steer_Wheel_Degree_Categorical\"] = pd.qcut(sub_df.Steer_Wheel_Degree, 2, labels=[\"Low\", \"High\"]) #2=High, 1 =Low\n",
    "        sub_df[\"Steer_Wheel_Degree_Encoded\"] = sub_df.Steer_Wheel_Degree_Categorical.replace({'High': 2, 'Low': 1})\n",
    "        all_dfs.append(sub_df)\n",
    "    return pd.concat(all_dfs).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def str_list_to_list(lst):\n",
    "    str_single_space = re.sub(\"\\s+\", \" \", lst.strip())\n",
    "    str_no_brackets = re.sub(\"[\\[\\]]\", \"\", lst)\n",
    "    return [float(n) for n in str_no_brackets.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4608af72-c0ae-443f-9e53-b6cea0773f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 77 columns\n",
      "6905 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/86xrfhcs2bl42hc35fbdmqz40000gn/T/ipykernel_72291/127439797.py:19: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  motor_epochs = mne.concatenate_epochs(motor_epochs)\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../output/batch_analysis_non_baseline_non_averaged/'\n",
    "remove_sessions = [(15,1),(22,1)]\n",
    "rel_regions = {'premotor_regions': ['FC3', 'FC1', 'FCz', 'FC2', 'FC4'], 'dorsolateral_prefrontal': ['AF3', 'AFz', 'AF4'], 'intermediate_frontal': ['F3', 'F1', 'Fz', 'F2', 'F4']}\n",
    "all_regions = sum(rel_regions.values(),[])\n",
    "\n",
    "pupil_df = pd.read_csv(f\"../output/pupil_exposure/participant_level_exposure_fits.csv\")\n",
    "trial_dfs = pd.read_csv(f\"{output_dir}all_results.csv\")\n",
    "motor_dfs = read_motor_csvs()\n",
    "motor_dfs['post_steer_event_raw'] = motor_dfs['post_steer_event_raw'].apply(str_list_to_list)\n",
    "motor_epochs = get_motor_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36208051",
   "metadata": {},
   "source": [
    "# Clean up dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a9aafc-5532-4331-94fc-d568a049d0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n",
      "Replacing existing metadata with 79 columns\n"
     ]
    }
   ],
   "source": [
    "# seaborn\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_palette(\"tab10\")\n",
    "from mna.utils.batch_feature_extraction import clean_up_adadrive_trials\n",
    "\n",
    "motor_outlier_cols = ['abs_sum_delta_steer_input']\n",
    "cols_to_outlier_detect = ['bpm', 'sdnn', 'rmssd', 'pnn50']\n",
    "experimental_cols = ['spoken_difficulty', 'trial_duration', 'density', 'trial_damage']\n",
    "eye_cols = ['Left Pupil Diameter', \"NSLR_count_Fixation\", \"NSLR_count_Saccade\",\n",
    "            'NSLR_mean_duration_Fixation', 'NSLR_mean_duration_Saccade',\n",
    "            'NSLR_first_onset_Fixation', 'NSLR_first_onset_Saccade']\n",
    "ecg_cols = ['bpm', 'sdnn', 'rmssd', 'pnn50']  # rmssd = parasympathetic\n",
    "motor_cols = ['abs_sum_delta_steer_input', 'abs_sum_delta_brake_input', 'abs_sum_delta_throttle_input']\n",
    "\n",
    "\n",
    "def clean_up_trials(input_df):\n",
    "    all_dfs_final = clean_up_adadrive_trials(input_df.copy())\n",
    "    # damage change\n",
    "    all_dfs_final = all_dfs_final.sort_values(by=['ppid', 'session', 'block', 'trial'])\n",
    "    # nan, outliers\n",
    "    #for col in motor_outlier_cols:\n",
    "    #    all_dfs_final[col] = all_dfs_final[col].mask(all_dfs_final[col].sub(all_dfs_final[col].mean()).div(all_dfs_final[col].std()).abs().gt(2))\n",
    "    #all_dfs_final['abs_sum_delta_brake_input'] = all_dfs_final['abs_sum_delta_brake_input'].mask(all_dfs_final['abs_sum_delta_brake_input']>.1)\n",
    "\n",
    "    all_dfs_final['NSLR_first_onset_Fixation'] = all_dfs_final['NSLR_first_onset_Fixation'] - all_dfs_final[\n",
    "        'trial_start_time']\n",
    "    all_dfs_final['NSLR_first_onset_Saccade'] = all_dfs_final['NSLR_first_onset_Saccade'] - all_dfs_final[\n",
    "        'trial_start_time']\n",
    "\n",
    "    all_dfs_final[\n",
    "        'throttle_over_brake'] = all_dfs_final.abs_sum_delta_throttle_input / all_dfs_final.abs_sum_delta_brake_input\n",
    "    return all_dfs_final\n",
    "\n",
    "\n",
    "trial_dfs = clean_up_trials(trial_dfs)\n",
    "trial_dfs = trial_dfs.loc[~trial_dfs.ppid_session.isin([f\"{es[0]}_{es[1]}\" for es in remove_sessions])]\n",
    "motor_dfs = clean_up_trials(motor_dfs)\n",
    "\n",
    "# luminance effect removal from pupil diameter\n",
    "trial_dfs['Raw Left Pupil Diameter'] = trial_dfs['Left Pupil Diameter']\n",
    "motor_dfs['Raw Left Pupil Diameter'] = motor_dfs['Left Pupil Diameter']\n",
    "p_val_criteria = 0.05\n",
    "for index, row in trial_dfs.reset_index(drop=True).iloc[1:].iterrows():\n",
    "    last_ppid = trial_dfs.iloc[index - 1].ppid\n",
    "    last_session = trial_dfs.iloc[index - 1].session\n",
    "    last_trial = trial_dfs.iloc[index - 1].trial\n",
    "    last_opacity = trial_dfs.iloc[index - 1].density\n",
    "    if ((row.ppid == last_ppid) & (row.session == last_session) & (row.trial == last_trial + 1)):  # if continuous\n",
    "        # if there is a significant effect of opacity on pupil\n",
    "        if pupil_df.loc[pupil_df['sub'] == last_ppid, 'p_opacities'].values < p_val_criteria:\n",
    "            this_opacity = row.density\n",
    "            this_pupil_diameter = row['Left Pupil Diameter']\n",
    "            weight = pupil_df.loc[pupil_df['sub'] == last_ppid, 'w_opacities']\n",
    "            adjustment = (this_opacity - last_opacity) * weight\n",
    "            trial_dfs.iloc[index, trial_dfs.columns.get_loc('Left Pupil Diameter')] -= adjustment\n",
    "            motor_dfs.loc[(motor_dfs.ppid == last_ppid) & (motor_dfs.session == last_session) & (\n",
    "                        motor_dfs.trial == last_trial + 1), 'Left Pupil Diameter'] -= adjustment  # update motor df too\n",
    "            motor_epochs.metadata.loc[(motor_epochs.metadata.ppid == last_ppid) &\n",
    "                                      (motor_epochs.metadata.session == last_session) &\n",
    "                                      (\n",
    "                                                  motor_epochs.metadata.trial == last_trial + 1), 'Left Pupil Diameter'] += adjustment  # update motor epochs too\n",
    "# pupil bins\n",
    "motor_dfs['pupil_bin'] = motor_dfs.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=['low', 'high']))\n",
    "trial_dfs['pupil_bin'] = trial_dfs.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=['low', 'high']))\n",
    "motor_epochs.metadata['pupil_bin'] = motor_epochs.metadata.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=['low', 'high']))\n",
    "motor_dfs['pupil_bin_encoded'] = motor_dfs.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=[0, 1]))\n",
    "trial_dfs['pupil_bin_encoded'] = trial_dfs.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=[0, 1]))\n",
    "motor_epochs.metadata['pupil_bin_encoded'] = motor_epochs.metadata.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=[0, 1]))\n",
    "preturn = 1000\n",
    "motor_epochs.apply_baseline((-(preturn / 1000), -((preturn - 250) / 1000)))\n",
    "\n",
    "# participant-level binning of motor data, replaces the session-level info already there\n",
    "motor_dfs = get_motor_intensity_info(motor_dfs)\n",
    "motor_epochs.metadata = get_motor_intensity_info(motor_epochs.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b2719d",
   "metadata": {},
   "source": [
    "# Export to MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf824b5a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_files_for_pp(x):\n",
    "    all_pps_files = [file_to_sess[v] for v in file_to_sess if file_to_sess[v][0] == x]\n",
    "    all_pps_files.sort(key = lambda x: x[1])\n",
    "    sorted_files = [next((filename for filename, pp_sess in file_to_sess.items() if pp_sess == apf), None) for apf in all_pps_files]\n",
    "    return sorted_files\n",
    "\n",
    "data_dir = \"../data/\"\n",
    "lsl_dir = \"../mna/LSLPresets/\"\n",
    "vid_dir = '../data/videos/'\n",
    "output_path = '../output/matlab_exports/'\n",
    "Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "onlyfiles = [f for f in listdir(data_dir) if isfile(join(data_dir, f)) and '.pkl' in f]\n",
    "file_to_sess = {f: (int(f.rsplit('Sbj_',1)[1].split('-')[0]),int(f.rsplit('Ssn_',1)[1].split('.')[0])) for f in onlyfiles}\n",
    "all_pps = list(set([file_to_sess[v][0] for v in file_to_sess]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51547e21",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant 12\n",
      "input_path ../data/08_25_2022_10_32_35-Exp_adadrive-Sbj_12-Ssn_01.dats.pkl\n",
      "input_path ../data/08_26_2022_11_53_52-Exp_adadrive-Sbj_12-Ssn_02.dats.pkl\n",
      "input_path ../data/09_02_2022_10_34_48-Exp_adadrive-Sbj_12-Ssn_03.dats.pkl\n",
      "Saved a total of 257 trials\n",
      "participant 13\n",
      "input_path ../data/09_09_2022_11_52_19-Exp_adadrive-Sbj_13-Ssn_1.dats.pkl\n",
      "input_path ../data/09_16_2022_14_17_15-Exp_adadrive-Sbj_13-Ssn_02.dats.pkl\n",
      "input_path ../data/09_22_2022_16_27_07-Exp_adadrive-Sbj_13-Ssn_03.dats.pkl\n",
      "Saved a total of 229 trials\n",
      "participant 14\n",
      "input_path ../data/09_05_2022_15_44_37-Exp_adadrive-Sbj_14-Ssn_01.dats.pkl\n",
      "input_path ../data/09_07_2022_16_41_37-Exp_adadrive-Sbj_14-Ssn_2.dats.pkl\n",
      "input_path ../data/09_13_2022_16_22_31-Exp_adadrive-Sbj_14-Ssn_3.dats.pkl\n",
      "Saved a total of 195 trials\n",
      "participant 15\n",
      "input_path ../data/09_07_2022_13_57_15-Exp_adadrive-Sbj_15-Ssn_1.dats.pkl\n",
      "This session has no usable trials.\n",
      "No trials found for this participant.\n",
      "participant 16\n",
      "input_path ../data/09_12_2022_14_43_23-Exp_adadrive-Sbj_16-Ssn_1.dats.pkl\n",
      "input_path ../data/09_17_2022_12_23_32-Exp_adadrive-Sbj_16-Ssn_2.dats.pkl\n",
      "input_path ../data/09_21_2022_14_26_45-Exp_adadrive-Sbj_16-Ssn_03.dats.pkl\n",
      "Saved a total of 331 trials\n",
      "participant 17\n",
      "input_path ../data/09_09_2022_14_24_33-Exp_adadrive-Sbj_17-Ssn_01.dats.pkl\n",
      "input_path ../data/09_13_2022_10_32_39-Exp_adadrive-Sbj_17-Ssn_2.dats.pkl\n",
      "input_path ../data/09_19_2022_09_37_27-Exp_adadrive-Sbj_17-Ssn_3.dats.pkl\n",
      "Saved a total of 232 trials\n",
      "participant 18\n",
      "input_path ../data/09_10_2022_10_39_30-Exp_adadrive-Sbj_18-Ssn_1.dats.pkl\n",
      "input_path ../data/09_17_2022_10_31_03-Exp_adadrive-Sbj_18-Ssn_2.dats.pkl\n",
      "input_path ../data/09_24_2022_11_31_56-Exp_adadrive-Sbj_18-Ssn_3.dats.pkl\n",
      "Saved a total of 183 trials\n",
      "participant 19\n",
      "input_path ../data/09_10_2022_13_26_45-Exp_adadrive-Sbj_19-Ssn_1.dats.pkl\n",
      "input_path ../data/09_16_2022_10_52_26-Exp_adadrive-Sbj_19-Ssn_02.dats.pkl\n",
      "input_path ../data/09_22_2022_11_56_12-Exp_adadrive-Sbj_19-Ssn_3.dats.pkl\n",
      "Saved a total of 212 trials\n",
      "participant 20\n",
      "input_path ../data/09_08_2022_13_28_01-Exp_adadrive-Sbj_20-Ssn_1.dats.pkl\n",
      "input_path ../data/09_13_2022_13_38_39-Exp_adadrive-Sbj_20-Ssn_2.dats.pkl\n",
      "input_path ../data/09_14_2022_13_17_39-Exp_adadrive-Sbj_20-Ssn_3.dats.pkl\n",
      "Saved a total of 232 trials\n",
      "participant 21\n",
      "input_path ../data/09_14_2022_09_54_46-Exp_adadrive-Sbj_21-Ssn_1.dats.pkl\n",
      "input_path ../data/09_15_2022_10_23_39-Exp_adadrive-Sbj_21-Ssn_2.dats.pkl\n",
      "input_path ../data/09_21_2022_09_34_48-Exp_adadrive-Sbj_21-Ssn_3.dats.pkl\n",
      "Saved a total of 297 trials\n",
      "participant 22\n",
      "input_path ../data/09_15_2022_15_31_24-Exp_adadrive-Sbj_22-Ssn_1.dats.pkl\n",
      "This session has no usable trials.\n",
      "No trials found for this participant.\n",
      "participant 23\n",
      "input_path ../data/09_19_2022_15_23_32-Exp_adadrive-Sbj_23-Ssn_1.dats.pkl\n",
      "input_path ../data/09_20_2022_15_49_16-Exp_adadrive-Sbj_23-Ssn_02.dats.pkl\n",
      "input_path ../data/09_27_2022_15_45_40-Exp_adadrive-Sbj_23-Ssn_03.dats.pkl\n",
      "Saved a total of 296 trials\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this finds the minimum trial per session to\n",
    "for pp in all_pps:\n",
    "    print(f\"participant {pp}\")\n",
    "    all_eeg_trials = []\n",
    "    all_motor_trials = []\n",
    "    labels = []\n",
    "    for selected_file in get_files_for_pp(pp):\n",
    "        selected_pp_sess = file_to_sess[selected_file]\n",
    "        input_path = data_dir + selected_file # pick a random file, idx 26 and\n",
    "\n",
    "        print(f\"input_path {input_path}\")\n",
    "        metadata_jsons = read_all_lslpresets(path_to_jsonfiles=lsl_dir)\n",
    "        with open(input_path, 'rb') as handle:\n",
    "            rns_data = pickle.load(handle)\n",
    "\n",
    "        for key in rns_data.keys():\n",
    "            rns_data[key].append(return_metadata_from_name(key, metadata_jsons))\n",
    "\n",
    "        eeg_channel_names = mne.channels.make_standard_montage('biosemi64').ch_names\n",
    "        eeg_df = pd.DataFrame(rns_data['BioSemi'][0], columns=rns_data['BioSemi'][1],\n",
    "                          index=rns_data['BioSemi'][2]['ChannelNames']).T\n",
    "        eeg_df = eeg_df.iloc[:,1:65]\n",
    "        eeg_df.columns = eeg_channel_names\n",
    "\n",
    "        motor_df = pd.DataFrame(rns_data['Unity_MotorInput'][0], columns=rns_data['Unity_MotorInput'][1],\n",
    "                                  index=rns_data['Unity_MotorInput'][2]['ChannelNames']).T\n",
    "\n",
    "        sub_trials = trial_dfs[(trial_dfs.ppid == selected_pp_sess[0]) & (trial_dfs.session == selected_pp_sess[1])]\n",
    "        if len(sub_trials)==0:\n",
    "            print('This session has no usable trials.')\n",
    "            continue\n",
    "        max_eeg_trial = int(sub_trials.trial_duration.min()*2048) # ensure same size\n",
    "        max_motor_trial = int(sub_trials.trial_duration.min()*40) # ensure same size\n",
    "        new_sample_rate = 100\n",
    "\n",
    "        for index,trial in sub_trials.iterrows():\n",
    "            # if we want to use start of each trial\n",
    "            #sub_eeg_df = eeg_df[(eeg_df.index >= trial.trial_start_time) & (eeg_df.index <= trial.trial_end_time)].iloc[:max_eeg_trial]\n",
    "            #sub_motor_df = motor_df[(motor_df.index >= trial.trial_start_time) & (motor_df.index <= trial.trial_end_time)].iloc[:max_motor_trial]\n",
    "\n",
    "            # maximize the data through splitting trial data\n",
    "            sub_eeg_df = eeg_df[(eeg_df.index >= trial.trial_start_time) & (eeg_df.index <= trial.trial_end_time)]\n",
    "            sub_motor_df = motor_df[(motor_df.index >= trial.trial_start_time) & (motor_df.index <= trial.trial_end_time)]\n",
    "\n",
    "            bin = 1\n",
    "            eeg_dfs = []\n",
    "            motor_dfs = []\n",
    "            while max_eeg_trial*bin <= sub_eeg_df.shape[0] and max_motor_trial*bin <= sub_motor_df.shape[0]: # until we have enough of trial duration left, chunk the longer trial into sub trials\n",
    "                sub_trial_eeg = sub_eeg_df.iloc[max_eeg_trial*(bin-1):max_eeg_trial*bin].to_numpy()\n",
    "                secs = sub_trial_eeg.shape[0]/2048 # Number of seconds in signal X\n",
    "                samps = int(secs*new_sample_rate)     # Number of samples to downsample\n",
    "                sub_trial_eeg = scipy.signal.resample(sub_trial_eeg, samps).T\n",
    "                eeg_dfs.append(sub_trial_eeg)\n",
    "\n",
    "                sub_trial_motor = sub_motor_df.iloc[max_motor_trial*(bin-1):max_motor_trial*bin].to_numpy()\n",
    "                secs = sub_trial_motor.shape[0]/40 # Number of seconds in signal X\n",
    "                samps = int(secs*new_sample_rate)     # Number of samples to downsample\n",
    "                sub_trial_motor = scipy.signal.resample(sub_trial_motor, samps).T\n",
    "                motor_dfs.append(sub_trial_motor)\n",
    "                bin += 1\n",
    "            if len(eeg_dfs) > 0:\n",
    "                all_eeg_trials.append(np.array(eeg_dfs))\n",
    "                all_motor_trials.append(np.array(motor_dfs))\n",
    "                labels.append(f\"{trial.ppid}_{trial.session}\")\n",
    "    if len(all_eeg_trials)>0:\n",
    "        shortest_session_trial_length = min([a.shape[2] for a in all_eeg_trials])\n",
    "        trimmed_trials = [a[:,:,:shortest_session_trial_length]for a in all_eeg_trials]\n",
    "        all_eeg_trials = np.concatenate(trimmed_trials)\n",
    "\n",
    "        shortest_session_trial_length = min([a.shape[2] for a in all_motor_trials])\n",
    "        trimmed_trials = [a[:,:,:shortest_session_trial_length]for a in all_motor_trials]\n",
    "        all_motor_trials = np.concatenate(trimmed_trials)\n",
    "        print(f\"Saved a total of {all_eeg_trials.shape[0]} trials\")\n",
    "        mdic = {\"eeg\": all_eeg_trials, \"motor\": all_motor_trials, \"labels\": labels, \"ppid\": pp,\"sample_rate\": new_sample_rate}\n",
    "        savemat(f\"{output_path}{trial.ppid}.mat\", mdic)\n",
    "    else:\n",
    "        print('No trials found for this participant.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2823145",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
