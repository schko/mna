{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install eeglib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import mne\n",
    "import numpy as np\n",
    "import autoreject\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "import sklearn\n",
    "from eeglib.features import (bandPower, hjorthActivity, hjorthMobility,\n",
    "                             hjorthComplexity, sampEn, LZC, DFA, _HFD, HFD, PFD,\n",
    "                             synchronizationLikelihood)\n",
    "from mne_features.univariate import (compute_pow_freq_bands, compute_hjorth_mobility, \n",
    "                                     compute_hjorth_complexity, compute_higuchi_fd, compute_higuchi_fd,\n",
    "                                     compute_samp_entropy)\n",
    "                            \n",
    "\n",
    "from mna.sessions.eye_session import process_session_eye\n",
    "from mna.sessions.eeg_session import process_session_eeg\n",
    "from mna.sessions.motor_session import process_session_motor\n",
    "from mna.sessions.ecg_session import process_session_ecg\n",
    "\n",
    "from mna.utils.batch_feature_extraction import clean_up_adadrive_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 1. Read a RN App, converted pkl file, and create the metadata and data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from mna.utils.rnapp_data_format import read_all_lslpresets, return_metadata_from_name, event_data_from_data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path ../data/08_26_2022_11_53_52-Exp_adadrive-Sbj_12-Ssn_02.dats.pkl\n"
     ]
    }
   ],
   "source": [
    "# single subject analysis\n",
    "\n",
    "preproc_ica = True\n",
    "\n",
    "data_dir = \"../data/\"\n",
    "lsl_dir = \"../mna/LSLPresets/\"\n",
    "output_dir = '../output/'\n",
    "if not os.path.isdir(output_dir): os.makedirs(output_dir)\n",
    "\n",
    "onlyfiles = [f for f in listdir(data_dir) if isfile(join(data_dir, f)) and '.pkl' in f]\n",
    "input_path = data_dir + onlyfiles[8] # pick a random file\n",
    "print(f\"input_path {input_path}\")\n",
    "metadata_jsons = read_all_lslpresets(path_to_jsonfiles=lsl_dir)\n",
    "\n",
    "with open(input_path, 'rb') as handle:\n",
    "    rns_data = pickle.load(handle)\n",
    "\n",
    "## Add metadata to data\n",
    "\n",
    "for key in rns_data.keys():\n",
    "    rns_data[key].append(return_metadata_from_name(key, metadata_jsons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 2. Create new events (trial start etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "event_df = event_data_from_data(rns_data)\n",
    "event_df['trial_damage'] = event_df.damage.diff().fillna(0)\n",
    "event_df['trial_duration'] = event_df.trial_end_time - event_df.trial_start_time\n",
    "percent_missing = event_df.notnull().sum() / len(event_df)\n",
    "summary_statistics = {}\n",
    "summary_statistics['voice_success_rate'] = percent_missing['voice_timestamp']\n",
    "if 'chunk_timestamp' in percent_missing:\n",
    "    summary_statistics['chunk_success_rate'] = percent_missing['chunk_timestamp']\n",
    "else:\n",
    "    summary_statistics['chunk_success_rate'] = 0\n",
    "\n",
    "# temporary fix for pilot phase where we had some incomplete data\n",
    "if 'block_condition' not in event_df:\n",
    "    event_df['block_condition'] = 'practice'\n",
    "    event_df.loc[5:,'block_condition'] = 'voice'\n",
    "\n",
    "event_df['spoken_difficulty_encoded'] = event_df.spoken_difficulty.replace(to_replace=['easy', 'hard', 'unknown'],\n",
    "                                                                      value=[1, 2, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and filter raw EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=89, n_times=3891602\n",
      "    Range : 0 ... 3891601 =      0.000 ...  1900.196 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 55 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 55.00 Hz\n",
      "- Upper transition bandwidth: 13.75 Hz (-6 dB cutoff frequency: 61.88 Hz)\n",
      "- Filter length: 6759 samples (3.300 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    8.8s finished\n"
     ]
    }
   ],
   "source": [
    "eeg_montage = 'biosemi64'\n",
    "eeg_channel = 'BioSemi'\n",
    "run_autoreject=True\n",
    "autoreject_epochs=20\n",
    "average_reference=True\n",
    "downsampling = True\n",
    "n_decim = 16\n",
    "low_cut= 1.\n",
    "hi_cut= 55.\n",
    "\n",
    "event_column='spoken_difficulty_encoded'\n",
    "\n",
    "event_detected = event_df[event_column].notnull()\n",
    "event_recognized_df = event_df[event_detected]\n",
    "\n",
    "eeg_channel_names = mne.channels.make_standard_montage(eeg_montage).ch_names\n",
    "df = pd.DataFrame(rns_data[eeg_channel][0], columns=rns_data[eeg_channel][1],\n",
    "                  index=rns_data[eeg_channel][2]['ChannelNames']).T\n",
    "starting_time_s = rns_data[eeg_channel][1][0]\n",
    "freq = rns_data[eeg_channel][2]['NominalSamplingRate']\n",
    "rna_channel_names = list(df.columns)\n",
    "rna_channel_names[1:65] = eeg_channel_names\n",
    "info = mne.create_info(ch_names=rna_channel_names, ch_types=['stim'] + ['eeg'] * 64 + ['ecg'] * 2 + ['misc'] * 22,\n",
    "                       sfreq=freq)\n",
    "info.set_montage(eeg_montage)\n",
    "\n",
    "raw = mne.io.RawArray(df.T * 1e-6, info)\n",
    "raw = raw.pick(['eeg'])\n",
    "\n",
    "if average_reference:\n",
    "    raw = raw.set_eeg_reference(ref_channels='average')  # set average reference\n",
    "if low_cut or hi_cut:\n",
    "    raw.filter(l_freq=low_cut, h_freq=hi_cut)\n",
    "if downsampling:\n",
    "    raw.resample(freq/n_decim)\n",
    "    freq /= n_decim\n",
    "    \n",
    "trial_start_time = event_recognized_df.trial_start_time - starting_time_s  # reference for mne\n",
    "event_values = event_recognized_df[event_column].values\n",
    "events = np.column_stack((trial_start_time.values * freq,\n",
    "                          np.zeros(len(event_recognized_df), dtype=int),\n",
    "                          event_values)).astype(int)\n",
    "event_dict = dict(easy=1, hard=2, unknown=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Processing and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Artifact Removal (ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
      "Selecting by number: 64 components\n",
      "Fitting ICA took 45.3s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Method</th>\n",
       "        <td>fastica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Fit</th>\n",
       "        <td>86 iterations on raw data (243225 samples)</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>ICA components</th>\n",
       "        <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Explained variance</th>\n",
       "        <td>100.0&nbsp;%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Available PCA components</th>\n",
       "        <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Channel types</th>\n",
       "        <td>eeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ICA components marked for exclusion</th>\n",
       "        <td>&mdash;</td>\n",
       "    </tr>\n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<ICA | raw data decomposition, method: fastica (fit in 86 iterations on 243225 samples), 64 ICA components explaining 100.0 % of variance (64 PCA components available), channel types: eeg, no sources marked for exclusion>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica = mne.preprocessing.ICA(n_components=64, random_state=64)\n",
    "ica.fit(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ica.plot_components(picks=range(0,10))\n",
    "\n",
    "# ica.plot_sources(epochs[:10], picks=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Template Matching Artifact Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median correlation with constructed map: 0.992\n",
      "Displaying selected ICs per subject.\n",
      "At least 1 IC detected for each subject.\n",
      "Median correlation with constructed map: 0.982\n",
      "Displaying selected ICs per subject.\n",
      "At least 1 IC detected for each subject.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (64 components)\n",
      "    Zeroing out 2 ICA components\n",
      "    Projecting back using 64 PCA components\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>67 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>64 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>128.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>1.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>55.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:31:40 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawArray | 64 x 243225 (1900.2 s), ~118.9 MB, data loaded>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if preproc_ica:\n",
    "\n",
    "    with open('../output/saved_files/pickle_files/24_features_32_3baseline/ica_epochs.pickle', 'rb') as handle:\n",
    "        all_proc_epochs = pickle.load(handle)\n",
    "    with open('../output/saved_files/pickle_files/24_features_32_3baseline/ica.pickle', 'rb') as handle:\n",
    "        all_ica = pickle.load(handle)\n",
    "    with open('../output/saved_files/pickle_files/24_features_32_3baseline/eog_comp.pickle', 'rb') as handle:\n",
    "        all_eog_comps = pickle.load(handle)\n",
    "    with open('../output/saved_files/pickle_files/24_features_32_3baseline/raw_epochs.pickle', 'rb') as handle:\n",
    "        all_raw_epochs = pickle.load(handle)\n",
    "\n",
    "    ref_ica = all_ica['sbj20ssn03']\n",
    "else: \n",
    "    ref_ica = None\n",
    "\n",
    "from mne.preprocessing import corrmap\n",
    "\n",
    "icas = [ref_ica]+[ica]\n",
    "corrmap(icas, template= (0,5), label = \"blink\", show=False)\n",
    "corrmap(icas, template= (0,4), label = \"horizontal_eye_movement\", show=False)\n",
    "identified_ica_label = [ica.labels_ for ica in icas]\n",
    "eog_idx = identified_ica_label[1]['blink']+identified_ica_label[1]['horizontal_eye_movement']\n",
    "\n",
    "ica.apply(raw, exclude=eog_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=89, n_times=3891602\n",
      "    Range : 0 ... 3891601 =      0.000 ...  1900.196 secs\n",
      "Ready.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 55 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 55.00 Hz\n",
      "- Upper transition bandwidth: 13.75 Hz (-6 dB cutoff frequency: 61.88 Hz)\n",
      "- Filter length: 6759 samples (3.300 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
      "Selecting by number: 64 components\n",
      "Fitting ICA took 43.2s.\n",
      "Median correlation with constructed map: 0.992\n",
      "Displaying selected ICs per subject.\n",
      "At least 1 IC detected for each subject.\n",
      "Median correlation with constructed map: 0.982\n",
      "Displaying selected ICs per subject.\n",
      "At least 1 IC detected for each subject.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (64 components)\n",
      "    Zeroing out 2 ICA components\n",
      "    Projecting back using 64 PCA components\n",
      "Not setting metadata\n",
      "49 matching events found\n",
      "Setting baseline interval to [-0.203125, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 49 events and 411 original time points ...\n",
      "0 bad epochs dropped\n",
      "Dropped 2 epochs: 27, 36\n"
     ]
    }
   ],
   "source": [
    "# Run EEG session Function\n",
    "\n",
    "_, epochs_func, _, _, _, ica_func, eog_idx_func= process_session_eeg_mod(rns_data, event_df, run_autoreject=True, run_ica=preproc_ica, \n",
    "                                                         template_ica = ref_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "49 matching events found\n",
      "Setting baseline interval to [-0.203125, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 49 events and 411 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# epochs = mne.Epochs(raw, events, event_id=event_dict, baseline = None, tmin=-0.5, tmax=3.5, prel oad=True, on_missing='warn')\n",
    "epochs = mne.Epochs(raw, events, event_id=event_dict, baseline = (None, 0), tmin=-0.2, tmax=3, preload=True, on_missing='warn')\n",
    "event_recognized_df = event_recognized_df[[e==() for e in epochs.drop_log]] # only keep good epochs in event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_base = raw.copy()\n",
    "# raw_no_base = raw.copy()\n",
    "\n",
    "# epochs_base = mne.Epochs(raw_base, events, event_id=event_dict, baseline = (None, 0), tmin=-0.2, tmax=3, preload=True, on_missing='warn')\n",
    "# epochs_no_base = mne.Epochs(raw_base, events, event_id=event_dict, baseline = None, tmin=-0.2, tmax=3, preload=True, on_missing='warn')\n",
    "\n",
    "# # epochs_base.plot(n_epochs=5, title='epochs with baseline interval')\n",
    "# # epochs_no_base.plot(n_epochs=5, title='epochs with no baseline interval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Automatic Feature Decection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Artifact Detection\n",
    "# eog_idx, eog_scores = ica.find_bads_eog(raw, ch_name = ['Fp1', 'Fp2'])\n",
    "# # ecg_idx, ecg_scores = ica.find_bads_ecg(raw, method='ctps', measure='correlation', threshold=\"auto\")\n",
    "# # muscle_idx, muscle_scores = ica.find_bads_muscle(raw)\n",
    "\n",
    "# # print([eog_idx, ecg_idx, muscle_idx])\n",
    "# print([eog_idx])\n",
    "\n",
    "# # ica.plot_scores(eog_scores, exclude=eog_idx)\n",
    "# # ica.plot_scores(ecg_scores, exclude=ecg_idx)\n",
    "# # ica.plot_scores(muscle_scores, exclude=muscle_idx)\n",
    "\n",
    "# # first half all non-ECG component (EOG component was identified as ECG component as well). second half eog component\n",
    "# # non_ECG_comp = list(set(np.arange(ica.n_components_)).symmetric_difference(set(ecg_idx))) + \\\n",
    "# #                list(set(ecg_idx).intersection(set(eog_idx)))\n",
    "\n",
    "\n",
    "# # Identified Artifact Component Removal\n",
    "# eeg_data_ICA = raw.copy()\n",
    "# # ica.apply(eeg_data_ICA, exclude=eog_idx+ecg_idx+muscle_idx)\n",
    "# # ica.apply(eeg_data_ICA, exclude=eog_idx+ecg_idx)\n",
    "# ica.apply(eeg_data_ICA, exclude=eog_idx)\n",
    "# # ica.apply(eeg_data_ICA, exclude=non_ECG_comp)\n",
    "\n",
    "# eeg_data_ICA_epochs = mne.Epochs(eeg_data_ICA, events, event_id=event_dict, baseline = (None, None), tmin=-3, tmax=0, preload=True, on_missing='warn')\n",
    "\n",
    "# del eeg_data_ICA\n",
    "\n",
    "# # plot before and after component removal signal\n",
    "# # epochs.plot(n_channels=10, n_epochs=5, show_scrollbars=False)\n",
    "# # eeg_data_ICA.plot(n_channels=10, n_epochs=5, show_scrollbars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Autoreject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 epochs: 27, 36\n"
     ]
    }
   ],
   "source": [
    "#Autoreject\n",
    "if len(epochs) < 10: # we need at least 10 epochs to run autoreject for cross validation\n",
    "    bad_epochs = pd.Series(np.full(len(event_df),np.NAN), index=event_df.index, name='autorejected')\n",
    "    event_df = event_df.join(bad_epochs)\n",
    "    reject_log = None\n",
    "\n",
    "elif run_autoreject:\n",
    "    ar = autoreject.AutoReject(random_state=11, n_jobs=2, verbose=False)\n",
    "    ar.fit(epochs[:autoreject_epochs])  # fit on a few epochs to save time\n",
    "    epochs_ar, reject_log = ar.transform(epochs, return_log=True)\n",
    "    bad_epochs = pd.Series(reject_log.bad_epochs, index=event_recognized_df.index, dtype=bool, name='autorejected')\n",
    "    event_df = event_df.join(bad_epochs) # creates nan if not processed at all\n",
    "    epochs = epochs_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.49722218e-06, -3.26845287e-06, -1.08378063e-05, -1.60299410e-05,\n",
       "        -8.31764352e-06,  8.70759447e-08,  7.86900538e-06,  8.14369486e-06,\n",
       "         4.44886541e-05,  6.31470223e-05]),\n",
       " array([-9.35159109e-06,  5.01027832e-06,  2.08964763e-06, -4.66157512e-06,\n",
       "         4.10122243e-06,  6.37426498e-06, -6.56415946e-06, -5.86166480e-07,\n",
       "        -5.84351875e-06, -3.70102744e-06]),\n",
       " array([-9.35159109e-06,  5.01027832e-06,  2.08964763e-06, -4.66157512e-06,\n",
       "         4.10122243e-06,  6.37426498e-06, -6.56415946e-06, -5.86166480e-07,\n",
       "        -5.84351875e-06, -3.70102744e-06]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.get_data()[0][:10], epochs.get_data()[0][0][:10], epochs_func.get_data()[0][0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Time-Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch\n",
    "\n",
    "epochs_easy = epochs_func['easy']\n",
    "epochs_hard = epochs_func['hard']\n",
    "\n",
    "# freq_range = np.logspace(*np.log10([4, 55]), num=15)\n",
    "freq_range = np.linspace(4, 56, 28)\n",
    "n_cycles = freq_range / 2.\n",
    "\n",
    "power_easy, itc_easy = tfr_morlet(epochs_easy, freqs=freq_range, n_cycles=n_cycles, use_fft=True, return_itc=True, n_jobs=1)\n",
    "power_hard, itc_hard = tfr_morlet(epochs_hard, freqs=freq_range, n_cycles=n_cycles, use_fft=True, return_itc=True, n_jobs=1)\n",
    "\n",
    "sel_chan = 12\n",
    "\n",
    "# power_easy.plot_topo(baseline=(-0.5, -.2), mode='mean', title='Average power')\n",
    "# power_easy.plot([sel_chan], baseline=(-3.2, -3), mode='mean', title=power_easy.ch_names[sel_chan])\n",
    "power_easy.plot([sel_chan], baseline=(-0.2, 0), mode='mean', title=power_easy.ch_names[sel_chan])\n",
    "# power_easy.plot([sel_chan], baseline=None, mode='mean', title=power_easy.ch_names[sel_chan])\n",
    "\n",
    "# power_hard.plot_topo(baseline=None, mode='mean', title='Average power')\n",
    "power_hard.plot([sel_chan], baseline=(-0.2, 0), mode='mean', title=power_hard.ch_names[sel_chan])\n",
    "# power_hard.plot([sel_chan], baseline=None, mode='mean', title=power_hard.ch_names[sel_chan])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EEG Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eeg_bands = {'theta': [4, 8],\n",
    "    'alpha': [8, 15],\n",
    "    'beta': [15, 32],\n",
    "    'gamma': [32, 55]}\n",
    "\n",
    "band_specific_epoch = {}\n",
    "\n",
    "for freq_band in eeg_bands.keys():\n",
    "    band_specific_epoch[freq_band] = np.squeeze(epochs.filter(eeg_bands[freq_band][0],eeg_bands[freq_band][1], \n",
    "                                                              verbose = False).get_data())\n",
    "    # band_specific_epoch[freq_band] = epochs.filter(eeg_bands[freq_band][0],eeg_bands[freq_band][1], verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs.filter(8,15, verbose = False).plot_psd()\n",
    "# band_specific_epoch['alpha'].plot_psd()\n",
    "\n",
    "# epochs.filter(8,15, verbose = False).get_data()[0].mean(), band_specific_epoch['theta'].get_data()[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import signal, fft\n",
    "\n",
    "# chan1_signal = band_specific_epoch['alpha'][0][1]\n",
    "# y_fft = fft.fft(chan1_signal)\n",
    "\n",
    "# # n = len(chan1_signal)\n",
    "# # all_freq = np.linspace(0,freq, n)\n",
    "# # plt.plot(all_freq, abs(y_fft))\n",
    "\n",
    "# freqs, psd = signal.welch(chan1_signal, freq, nfft=1024, nperseg=1024, window='hamming')\n",
    "# len(freqs), len(psd)\n",
    "# plt.plot(freqs, psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_limits = [4, 8, 15, 32, 55]\n",
    "\n",
    "def eeg_features(bands_limits):\n",
    "    \n",
    "    win_size = 1024\n",
    "    bands = np.asarray(bands_limits)\n",
    "    band_intervals = list(zip(bands[:-1], bands[1:]))\n",
    "\n",
    "    band_power_all = np.empty([len(epochs), len(eeg_channel_names)*len(band_intervals)])\n",
    "    hjorth_activity = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    hjorth_mobility = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    hjorth_complexity = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    higuchi_fd = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    sample_entropy = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "\n",
    "    channel_band_power = [f\"{chan_name}_{each_band[0]}-{each_band[1]}_Hz_Power\"\n",
    "                              for chan_name in eeg_channel_names\n",
    "                                  for each_band in band_intervals]\n",
    "    band_specific_features_list = ['Hjorth_Activity', 'Hjorth_Mobility', 'Hjorth_Complexity', \n",
    "                                   'Higuchi_FD', 'Sample_entropy']\n",
    "    band_specific_features = [f\"{chan_name}_{each_band[0]}-{each_band[1]}_Hz_{each_feature}\"\n",
    "                          for each_feature in band_specific_features_list\n",
    "                              for each_band in band_intervals\n",
    "                                  for chan_name in eeg_channel_names]\n",
    "    \n",
    "    all_features_list = channel_band_power + band_specific_features\n",
    "\n",
    "    # band power calculation\n",
    "    for i in range(len(epochs)):\n",
    "        eeg_data = np.squeeze(epochs[i].get_data())\n",
    "        band_power = compute_pow_freq_bands(sfreq=freq, data=eeg_data, freq_bands=bands, normalize=False,\n",
    "                                            psd_params={'welch_n_fft': win_size, 'welch_n_per_seg': win_size})\n",
    "        band_power_all[i, :] = band_power\n",
    "\n",
    "    for index, freq_band in enumerate(band_intervals):\n",
    "        band_specific_epoch = np.squeeze(epochs.filter(freq_band[0],freq_band[1], verbose = False).get_data())\n",
    "        for i in range(len(epochs.events)):\n",
    "            for ii in range(64):\n",
    "                # band-specific Hjorth activity, mobility and complexity\n",
    "                hjorth_activity[i,ii] = hjorthActivity(band_specific_epoch[i][ii])\n",
    "                hjorth_mobility[i,ii] = hjorthMobility(band_specific_epoch[i][ii])\n",
    "                hjorth_complexity[i,ii] = hjorthComplexity(band_specific_epoch[i][ii])\n",
    "\n",
    "                # band-specific HFD\n",
    "                higuchi_fd[i,ii] = HFD(band_specific_epoch[i][ii])\n",
    "\n",
    "                # band-specific sample entropy\n",
    "                sample_entropy[i,ii] = sampEn(band_specific_epoch[i][ii])\n",
    "\n",
    "        if index == 0:\n",
    "            hjorth_activity_all = hjorth_activity\n",
    "            hjorth_mobility_all = hjorth_mobility\n",
    "            hjorth_complexity_all = hjorth_complexity\n",
    "            higuchi_fd_all = higuchi_fd\n",
    "            sample_entropy_all = sample_entropy\n",
    "        else:\n",
    "            hjorth_activity_all = np.hstack((hjorth_activity_all, hjorth_activity))\n",
    "            hjorth_mobility_all = np.hstack((hjorth_mobility_all, hjorth_mobility))\n",
    "            hjorth_complexity_all = np.hstack((hjorth_complexity_all, hjorth_complexity))\n",
    "            higuchi_fd_all = np.hstack((higuchi_fd_all, higuchi_fd))\n",
    "            sample_entropy_all = np.hstack((sample_entropy_all, sample_entropy))\n",
    "\n",
    "    all_eeg_features = np.hstack((band_power_all, hjorth_activity_all, hjorth_mobility_all,\n",
    "                                  hjorth_complexity_all, higuchi_fd_all, sample_entropy_all)) \n",
    "    all_eeg_features_df = pd.DataFrame(all_eeg_features, index=event_recognized_df.index, columns=all_features_list)\n",
    "\n",
    "    return all_eeg_features_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eeg_features_df = eeg_features(bands_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Band Power\n",
    "# win_size = 1024\n",
    "# band_power_epochs = np.empty([len(epochs), len(eeg_channel_names)*len(band_intervals)])\n",
    "\n",
    "# for i in range(len(epochs)):\n",
    "#     data_mne = np.squeeze(epochs[i].get_data())\n",
    "\n",
    "#     # EEG bands\n",
    "#     pow_freq_band = compute_pow_freq_bands(sfreq=freq, data=data_mne, freq_bands=bands, normalize=False,\n",
    "#                                                 psd_params={'welch_n_fft': win_size, 'welch_n_per_seg': win_size})\n",
    "#     band_power_epochs[i, :] = pow_freq_band\n",
    "\n",
    "# # band-specific Hjorth activity, mobility and complexity\n",
    "# hjorth_activity_dict = {}\n",
    "# hjorth_mobility_dict = {}\n",
    "# hjorth_complexity_dict = {}\n",
    "\n",
    "# hjorth_activity = np.empty([len(epochs.events),64])\n",
    "# hjorth_mobility = np.empty([len(epochs.events),64])\n",
    "# hjorth_complexity = np.empty([len(epochs.events),64])\n",
    "\n",
    "# for freq_band in eeg_bands.keys():\n",
    "#     for i in range(len(epochs.events)):\n",
    "#         for ii in range(64):\n",
    "#             hjorth_activity[i,ii] = hjorthActivity(band_specific_epoch[freq_band][i][ii])\n",
    "#             hjorth_mobility[i,ii] = hjorthMobility(band_specific_epoch[freq_band][i][ii])\n",
    "#             hjorth_complexity[i,ii] = hjorthComplexity(band_specific_epoch[freq_band][i][ii])\n",
    "        \n",
    "#     hjorth_activity_dict[freq_band] = hjorth_activity\n",
    "#     hjorth_mobility_dict[freq_band] = hjorth_mobility\n",
    "#     hjorth_complexity_dict[freq_band] = hjorth_complexity\n",
    "\n",
    "# # band-specific HFD\n",
    "# higuchi_fd_dict = {}\n",
    "# higuchi_fd = np.empty([len(epochs.events),64])\n",
    "\n",
    "# for freq_band in eeg_bands.keys():\n",
    "#     for i in range(len(epochs.events)):\n",
    "#         for ii in range(64):\n",
    "#             higuchi_fd[i,ii] = HFD(band_specific_epoch[freq_band][i][ii])\n",
    "#     higuchi_fd_dict[freq_band] = higuchi_fd\n",
    "\n",
    "# # band-specific sample entropy\n",
    "# sample_entropy_dict = {}\n",
    "# sample_entropy = np.empty([len(epochs.events),64])\n",
    "\n",
    "# for freq_band in eeg_bands.keys():\n",
    "#     for i in range(len(epochs.events)):\n",
    "#         for ii in range(64):\n",
    "#             sample_entropy[i,ii] = sampEn(band_specific_epoch[freq_band][i][ii])\n",
    "#     sample_entropy_dict[freq_band] = sample_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Pupil Diameter Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eye_channel='Unity_ViveSREyeTracking'\n",
    "df_eye = pd.DataFrame(rns_data[eye_channel][0], columns=rns_data[eye_channel][1],\n",
    "                      index=rns_data[eye_channel][2]['ChannelNames']).T\n",
    "\n",
    "n_samples = rns_data[eye_channel][2]['NominalSamplingRate']*6\n",
    "\n",
    "label = np.empty(len(event_df.index)-1)\n",
    "trials_left_pupil = []\n",
    "trials_right_pupil = []\n",
    "\n",
    "#Skip last trial because it's empty\n",
    "for i in range(len(event_df.index)-1):\n",
    "    L_Pupil_Diameter = df_eye['L Pupil Diameter'][(df_eye.index >= event_df['trial_start_time'][i]) &\n",
    "                                                  (df_eye.index <= event_df['trial_end_time'][i]) &\n",
    "                                                  (df_eye['L Pupil Diameter'] != -1)]\n",
    "    trials_left_pupil.append(L_Pupil_Diameter)\n",
    "\n",
    "#     R_Pupil_Diameter = np.asarray(df_eye['R Pupil Diameter'][(df_eye.index >= event_df['trial_start_time'][i]) &\n",
    "#                                          (df_eye.index <= event_df['trial_end_time'][i]) &\n",
    "#                                                    (df_eye['R Pupil Diameter'] > -1)].replace(-1, np.nan))\n",
    "#     trials_right_pupil[i, :] = R_Pupil_Diameter[:n_samples]\n",
    "\n",
    "#     label[i] = event_df.spoken_difficulty_encoded[i]\n",
    "\n",
    "# trials_left_pupil = trials_left_pupil[pd.isna(label)==False]\n",
    "# trials_right_pupil = trials_right_pupil[pd.isna(label)==False]\n",
    "# label = label[pd.isna(label)==False].astype(int)\n",
    "\n",
    "trials_left_pupil[32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Trial Difficulty Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from mne_features.univariate import compute_hjorth_mobility,compute_pow_freq_bands\n",
    "\n",
    "# Dataset Split - EEG\n",
    "x_train_raw, x_test_raw, y_train_raw, y_test_raw = train_test_split(epochs.get_data()[:,:64,:], epochs.events[:,2], random_state=64, test_size=10)\n",
    "x_train_AR, x_test_AR, y_train_AR, y_test_AR = train_test_split(eeg_data_ICA_epochs.get_data()[:,:64,:], eeg_data_ICA_epochs.events[:,2],\n",
    "                                                                    random_state=64, test_size=10)\n",
    "\n",
    "# Dataset Split - Pupil Diameter\n",
    "x_train_pupil, x_test_pupil, y_train_pupil, y_test_pupil = train_test_split(trials_left_pupil, label, random_state=64, test_size=10)\n",
    "\n",
    "# Feature extraction\n",
    "def eeg_feature(train_raw, test_raw, train_ar, test_ar, method, band_intervals = None):\n",
    "\n",
    "    if method == 'psd':\n",
    "\n",
    "        band_freq = band_intervals\n",
    "\n",
    "        train_feature_raw = np.empty([len(train_raw), len(eeg_channel_names)*(len(band_freq)-1)])\n",
    "        test_feature_raw = np.empty([len(test_raw), len(eeg_channel_names)*(len(band_freq)-1)])\n",
    "        train_feature_ar = np.empty([len(train_ar), len(eeg_channel_names)*(len(band_freq)-1)])\n",
    "        test_feature_ar = np.empty([len(test_ar), len(eeg_channel_names)*(len(band_freq)-1)])\n",
    "\n",
    "        for i in range(len(train_raw)):\n",
    "\n",
    "            train_feature_raw[i,:] = compute_pow_freq_bands(freq, train_raw[i], freq_bands = band_freq)\n",
    "            train_feature_ar[i,:] = compute_pow_freq_bands(freq, train_ar[i], freq_bands = band_freq)\n",
    "\n",
    "        for j in range(len(test_raw)):\n",
    "            test_feature_raw[j,:] = compute_pow_freq_bands(freq, test_raw[j], freq_bands = band_freq)\n",
    "            test_feature_ar[j,:] = compute_pow_freq_bands(freq, test_ar[j], freq_bands = band_freq)\n",
    "\n",
    "    if method == 'hjorth_mobility':\n",
    "        train_feature_raw = compute_hjorth_mobility(train_raw)\n",
    "        test_feature_raw = compute_hjorth_mobility(test_raw)\n",
    "\n",
    "        train_feature_ar = compute_hjorth_mobility(train_ar)\n",
    "        test_feature_ar = compute_hjorth_mobility(test_ar)\n",
    "\n",
    "    if method == \"temporal_avg\":\n",
    "        train_feature_raw = np.mean(x_train_AR, axis = -1)\n",
    "        test_feature_raw = np.mean(x_test_AR, axis = -1)\n",
    "\n",
    "        train_feature_ar = np.mean(x_train_raw, axis = -1)\n",
    "        test_feature_ar = np.mean(x_test_raw, axis = -1)\n",
    "\n",
    "    return train_feature_raw, test_feature_raw, train_feature_ar, test_feature_ar\n",
    "\n",
    "# call function for eeg feature extraction\n",
    "raw_train_feature, raw_test_feature, AR_train_feature, AR_test_feature = eeg_feature(x_train_raw, x_test_raw, \n",
    "                                                                                     x_train_AR, x_test_AR, \n",
    "                                                                                     'psd', band_intervals = np.array([3,8,13,30,64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "# Trial Difficulty Classification Function\n",
    "def spoken_difficulty_classification(train_data, test_data, train_label, test_label, method):\n",
    "\n",
    "    if method == 'logistic':\n",
    "\n",
    "        logreg = LogisticRegression(solver=\"liblinear\", random_state=0).fit(train_data, train_label)\n",
    "        score_train = logreg.decision_function(train_data)\n",
    "        score_test = logreg.decision_function(test_data)\n",
    "\n",
    "        train_pred = logreg.predict(train_data)\n",
    "        test_pred = logreg.predict(test_data)\n",
    "\n",
    "    if method == 'svm':\n",
    "\n",
    "        svm_classifer = SGDClassifier(random_state=0).fit(train_data, train_label)\n",
    "        score_train = svm_classifer.decision_function(train_data)\n",
    "        score_test = svm_classifer.decision_function(test_data)\n",
    "\n",
    "        train_pred = svm_classifer.predict(train_data)\n",
    "        test_pred = svm_classifer.predict(test_data)\n",
    "\n",
    "    if method == 'knn':\n",
    "        kNN = KNeighborsClassifier(n_neighbors = 3).fit(train_data, train_label)\n",
    "\n",
    "        score_train = kNN.predict_proba(train_data)[:,1]\n",
    "        score_test = kNN.predict_proba(test_data)[:,1]\n",
    "\n",
    "        train_pred = (score_train > 0.5) + 0\n",
    "        test_pred = (score_test >0.5) + 0\n",
    "\n",
    "    fpr_train, tpr_train, thresholds_train = metrics.roc_curve(train_label-1, score_train)\n",
    "    ROC_score_train = metrics.roc_auc_score (train_label-1, score_train)\n",
    "\n",
    "    fpr_test, tpr_test, thresholds_test = metrics.roc_curve(test_label-1, score_test)\n",
    "    ROC_score_test = metrics.roc_auc_score (test_label-1, score_test)\n",
    "\n",
    "    train_acc = metrics.accuracy_score(train_label,train_pred)\n",
    "    test_acc = metrics.accuracy_score(test_label,test_pred)\n",
    "\n",
    "    # ROC Curve\n",
    "    fig = plt.figure(figsize = [10 ,3])\n",
    "\n",
    "    axe = fig.add_subplot(1,2,1)\n",
    "    axe.plot(fpr_train,tpr_train)\n",
    "    axe.set_xlabel(\"False Positive Rate\")\n",
    "    axe.set_ylabel(\"True Positive Rate\")\n",
    "    axe.set_title(\"Training ROC Curve\")\n",
    "    axe.text(0.6,0.2,\"ROC Score = {:.2f}\".format(ROC_score_train))\n",
    "\n",
    "    axe = fig.add_subplot(1,2,2)\n",
    "    axe.plot(fpr_test,tpr_test)\n",
    "    axe.set_xlabel(\"False Positive Rate\")\n",
    "    axe.set_ylabel(\"True Positive Rate\")\n",
    "    axe.set_title(\"Testing ROC Curve\")\n",
    "    axe.text(0.6,0.2,\"ROC Score = {:.2f}\".format(ROC_score_test))\n",
    "\n",
    "    # plt.grid(visible=False)\n",
    "    # Confusion Matrix\n",
    "    # fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    fig_cnf = plt.figure(figsize = [10 ,3])\n",
    "    ax1 = fig_cnf.add_subplot(1,2,1)\n",
    "    ax2 = fig_cnf.add_subplot(1,2,2)\n",
    "\n",
    "    cnf_matrix_train = metrics.confusion_matrix(train_label, train_pred)\n",
    "    cnf_matrix_test = metrics.confusion_matrix(test_label, test_pred)\n",
    "\n",
    "    sns.heatmap(cnf_matrix_train, annot = True, xticklabels = ['Easy','Hard'], yticklabels = ['Easy','Hard'],ax=ax1)\n",
    "    ax1.set_title(\"Training Confusion Matrix\")\n",
    "    sns.heatmap(cnf_matrix_test, annot = True, xticklabels = ['Easy','Hard'], yticklabels = ['Easy','Hard'],ax=ax2)\n",
    "    ax2.set_title(\"Testing Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return test_pred, train_pred, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Trial Difficulty Classification - Pupil Diameter\n",
    "test_pred_raw, train_pred_raw, train_acc_raw, test_acc_raw = spoken_difficulty_classification(x_train_pupil, x_test_pupil,y_train_pupil, y_test_pupil, 'logistic')\n",
    "\n",
    "# print(f\"Training Accuracy with Pupil Diameter: {train_acc_raw:.2f} \\n\"\n",
    "#       f\"Train Label:      {y_train_raw} \\n\"\n",
    "#       f\"Train Prediction: {train_pred_raw} \\n\"\n",
    "#       f\"Test Accuracy with Pupil Diameter: {test_acc_raw:.2f} \\n\"\n",
    "#       f\"Test Label:      {y_test_raw} \\n\"\n",
    "#       f\"Test Prediction: {test_pred_raw}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Trial Difficulty Classification - Raw EEG\n",
    "test_pred_raw, train_pred_raw, train_acc_raw, test_acc_raw = spoken_difficulty_classification(raw_train_feature, raw_test_feature,y_train_raw, y_test_raw, 'logistic')\n",
    "\n",
    "# print(f\"Training Accuracy without Artifacts Removal: {train_acc_raw:.2f} \\n\"\n",
    "#       f\"Train Label:      {y_train_raw} \\n\"\n",
    "#       f\"Train Prediction: {train_pred_raw} \\n\"\n",
    "#       f\"Test Accuracy without Artifacts Removal: {test_acc_raw:.2f} \\n\"\n",
    "#       f\"Test Label:      {y_test_raw} \\n\"\n",
    "#       f\"Test Prediction: {test_pred_raw}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Trial Difficulty Classification - Artifacts Removed EEG\n",
    "\n",
    "test_pred_AR, train_pred_AR, train_acc_AR, test_acc_AR = spoken_difficulty_classification(AR_train_feature, AR_test_feature,y_train_AR, y_test_AR, 'logistic')\n",
    "\n",
    "# print(f\"Training Accuracy with Artifacts Removal: {train_acc_AR:.2f} \\n\"\n",
    "#       f\"Training Label:      {y_train_AR} \\n\"\n",
    "#       f\"Training Prediction: {train_pred_AR} \\n\"\n",
    "#       f\"Test Accuracy with Artifacts Removal: {test_acc_AR:.2f} \\n\"\n",
    "#       f\"Test Label:      {y_test_AR} \\n\"\n",
    "#       f\"Test Prediction: {test_pred_AR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## ICA-Adaptive Filter - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install EMD-signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install EMD-signal\n",
    "# # import PyEMD\n",
    "# from PyEMD import EMD, Visualisation\n",
    "\n",
    "# eeg_comps = ica.get_sources(raw).get_data() #eeg componenets for all epochs\n",
    "# # eeg_comps = ica.get_sources(epochs).get_data() #eeg componenets for all epochs\n",
    "# # comps_epoch_concat = np.empty([eeg_comps.shape[1],eeg_comps.shape[2]*eeg_comps.shape[0]]) #initiate empty array\n",
    "# # for i in range(eeg_comps.shape[0]):\n",
    "# #     comps_epoch_concat[:,i*eeg_comps.shape[2]:eeg_comps.shape[2]*(i+1)] = eeg_comps[i]\n",
    "\n",
    "# component_no = 5\n",
    "# test_comps = eeg_comps[component_no]\n",
    "\n",
    "# emd = EMD() # EMD instantiation\n",
    "# emd.emd(test_comps) # decompose signal into IMFs and residue\n",
    "# imfs, res = emd.get_imfs_and_residue()\n",
    "\n",
    "# # # imfs = emd(np.squeeze(eeg_comps[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# scipy.stats.kurtosis(test_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Visualization\n",
    "# t = np.arange(0, 3+1/freq, 1/freq)\n",
    "# vis = Visualisation()\n",
    "# vis.plot_imfs(imfs=imfs, residue=res, t=t, include_residue=True)\n",
    "# # vis.plot_instant_freq(t, imfs=imfs)\n",
    "# vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "# EEG session Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_session_eeg_mod(rns_data, event_df, event_column='spoken_difficulty_encoded', eeg_channel='BioSemi',\n",
    "                        eeg_montage='biosemi64', save_path='../output/', sbj_session = None, save_raw_eeg = False,\n",
    "                        run_autoreject=True, autoreject_epochs=20, run_ica=True, template_ica = None, average_reference=True,\n",
    "                        downsampling = True, n_decim = 16, low_cut=1., hi_cut=55., plot_epochs=False, bands_limits=None, \n",
    "                        analyze_pre_ica = False, eye_movement_removal=True, tmin=-.2, tmax=3, baseline=(None, 0),\n",
    "                        normalize_pow_freq=True, filter_events=True):\n",
    "\n",
    "    if bands_limits is None:\n",
    "        bands_limits = [4, 8, 15, 32, 55]\n",
    "    if filter_events:\n",
    "        event_detected = event_df[event_column].notnull()\n",
    "        event_recognized_df = event_df[event_detected]\n",
    "    else:\n",
    "        event_recognized_df = event_df\n",
    "\n",
    "    eeg_channel_names = mne.channels.make_standard_montage(eeg_montage).ch_names\n",
    "    df = pd.DataFrame(rns_data[eeg_channel][0], columns=rns_data[eeg_channel][1],\n",
    "                      index=rns_data[eeg_channel][2]['ChannelNames']).T\n",
    "    starting_time_s = rns_data[eeg_channel][1][0]\n",
    "    freq = rns_data[eeg_channel][2]['NominalSamplingRate']\n",
    "    rna_channel_names = list(df.columns)\n",
    "    rna_channel_names[1:65] = eeg_channel_names\n",
    "    info = mne.create_info(ch_names=rna_channel_names, ch_types=['stim'] + ['eeg'] * 64 + ['ecg'] * 2 + ['misc'] * 22,\n",
    "                           sfreq=freq)\n",
    "    info.set_montage(eeg_montage)\n",
    "\n",
    "    raw = mne.io.RawArray(df.T * 1e-6, info)\n",
    "    raw = raw.pick('eeg')\n",
    "    if average_reference:\n",
    "        raw = raw.set_eeg_reference(ref_channels='average')  # set average reference\n",
    "    if low_cut or hi_cut:\n",
    "        raw.filter(l_freq=low_cut, h_freq=hi_cut)\n",
    "    if downsampling:\n",
    "        raw.resample(freq/n_decim)\n",
    "        freq /= n_decim\n",
    "\n",
    "    trial_start_time = event_recognized_df.trial_start_time - starting_time_s  # reference for mne\n",
    "    event_values = event_recognized_df[event_column].values\n",
    "    events = np.column_stack((trial_start_time.values * freq,\n",
    "                              np.zeros(len(event_recognized_df), dtype=int),\n",
    "                              event_values)).astype(int)\n",
    "    event_dict = dict(easy=1, hard=2, unknown=0)\n",
    "    \n",
    "\n",
    "    if run_ica:\n",
    "        \n",
    "        # Fit ICA\n",
    "        ica = mne.preprocessing.ICA(n_components=64, random_state=64) # n_components as a decimal set % explained variance\n",
    "        ica.fit(raw)\n",
    "        \n",
    "        # Semi automatic artifact detection - Corrmap\n",
    "        if (sbj_session == 'sbj20ssn03') or (template_ica == None):\n",
    "            if eye_movement_removal:\n",
    "                eog_idx = [4, 5]\n",
    "            else:\n",
    "                eog_idx = [5]\n",
    "        else:\n",
    "            icas = [template_ica]+[ica]\n",
    "            corrmap(icas, template= (0,5), label = \"blink\", show=False)\n",
    "            \n",
    "            if eye_movement_removal:\n",
    "                corrmap(icas, template= (0,4), label = \"horizontal_eye_movement\", show=False)\n",
    "            identified_ica_label = [ica.labels_ for ica in icas]\n",
    "            \n",
    "            if eye_movement_removal:\n",
    "                eog_idx = identified_ica_label[1]['blink']+identified_ica_label[1]['horizontal_eye_movement']\n",
    "            else:\n",
    "                eog_idx = identified_ica_label[1]['blink']\n",
    "        \n",
    "        # Reconstruct filtered raw signal without Eye Components\n",
    "        ica.apply(raw, exclude=eog_idx)\n",
    "\n",
    "    else:\n",
    "        ica = None\n",
    "        eog_idx = None\n",
    "    \n",
    "    epochs = mne.Epochs(raw, events, event_id=event_dict, tmin=tmin, tmax=tmax, baseline=baseline, preload=True, \n",
    "                            on_missing='warn')\n",
    "\n",
    "    event_recognized_df = event_recognized_df[[e==() for e in epochs.drop_log]] # only keep good epochs in event_df\n",
    "    reject_log = None\n",
    "\n",
    "    # EEG Feature Extraction - 24 features\n",
    "    extracted_24_features_df = eeg_features(epochs, event_recognized_df, bands_limits, eeg_channel_names, freq, normalize_pow_freq=normalize_pow_freq)\n",
    "\n",
    "    if len(epochs) < 10: # we need at least 10 epochs to run autoreject for cross validation\n",
    "        bad_epochs = pd.Series(np.full(len(event_df),np.NAN), index=event_df.index, name='autorejected')\n",
    "        event_df = event_df.join(bad_epochs)\n",
    "        reject_log = None\n",
    "    elif run_autoreject:\n",
    "        ar = autoreject.AutoReject(random_state=11,\n",
    "                                   n_jobs=1, verbose=False)\n",
    "        ar.fit(epochs[:autoreject_epochs])  # fit on a few epochs to save time\n",
    "        epochs_ar, reject_log = ar.transform(epochs, return_log=True)\n",
    "        bad_epochs = pd.Series(reject_log.bad_epochs, index=event_recognized_df.index, dtype=bool, name='autorejected')\n",
    "        event_df = event_df.join(bad_epochs)\n",
    "        epochs = epochs_ar\n",
    "    \n",
    "    event_df = event_df.join(extracted_24_features_df)\n",
    "\n",
    "    return event_df, epochs, events, info, reject_log, ica, eog_idx\n",
    "\n",
    "def eeg_features(epochs, event_recognized_df, bands_limits, eeg_channel_names, fs, win_size = 1024, normalize_pow_freq=True):\n",
    "    \n",
    "    # identify available frequency bands\n",
    "    bands = np.asarray(bands_limits)\n",
    "    band_intervals = list(zip(bands[:-1], bands[1:]))\n",
    "    \n",
    "    #initiate empty matrix for all features\n",
    "    band_power_all = np.empty([len(epochs), len(eeg_channel_names)*len(band_intervals)])\n",
    "    hjorth_activity = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    hjorth_mobility = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    hjorth_complexity = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    higuchi_fd = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    sample_entropy = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    \n",
    "    # create column list for dataframe (band power column arrangement will be different than others due to its function)\n",
    "    channel_band_power = [f\"{chan_name}_{each_band[0]}-{each_band[1]}_Hz_Power\"\n",
    "                              for chan_name in eeg_channel_names\n",
    "                                  for each_band in band_intervals]\n",
    "    band_specific_features_list = ['Hjorth_Activity', 'Hjorth_Mobility', 'Hjorth_Complexity', \n",
    "                                   'Higuchi_FD', 'Sample_entropy']\n",
    "    band_specific_features = [f\"{chan_name}_{each_band[0]}-{each_band[1]}_Hz_{each_feature}\"\n",
    "                          for each_feature in band_specific_features_list\n",
    "                              for each_band in band_intervals\n",
    "                                  for chan_name in eeg_channel_names]\n",
    "    # combine column name for all features\n",
    "    all_features = channel_band_power + band_specific_features\n",
    "\n",
    "    # band power calculation\n",
    "    for i in range(len(epochs)):\n",
    "        eeg_data = np.squeeze(epochs.get_data(item=i))\n",
    "        band_power = compute_pow_freq_bands(sfreq=fs, data=eeg_data, freq_bands=bands, normalize=normalize_pow_freq,\n",
    "                                            psd_params={'welch_n_fft': win_size, 'welch_n_per_seg': win_size})\n",
    "        band_power_all[i, :] = band_power\n",
    "    \n",
    "    # Other features calculation\n",
    "    for index, freq_band in enumerate(band_intervals):\n",
    "        band_specific_epoch = np.squeeze(epochs.copy().filter(freq_band[0],freq_band[1], verbose = False).get_data())\n",
    "        for i in range(len(epochs.events)):\n",
    "            for ii in range(64):\n",
    "                # band-specific Hjorth activity, mobility and complexity\n",
    "                hjorth_activity[i,ii] = hjorthActivity(band_specific_epoch[i][ii])\n",
    "                hjorth_mobility[i,ii] = hjorthMobility(band_specific_epoch[i][ii])\n",
    "                hjorth_complexity[i,ii] = hjorthComplexity(band_specific_epoch[i][ii])\n",
    "\n",
    "                # band-specific HFD\n",
    "                higuchi_fd[i,ii] = HFD(band_specific_epoch[i][ii])\n",
    "\n",
    "                # band-specific sample entropy\n",
    "                sample_entropy[i,ii] = sampEn(band_specific_epoch[i][ii])\n",
    "    # concatenate each band specific features into a single matrix \n",
    "        if index == 0:\n",
    "            hjorth_activity_all = hjorth_activity\n",
    "            hjorth_mobility_all = hjorth_mobility\n",
    "            hjorth_complexity_all = hjorth_complexity\n",
    "            higuchi_fd_all = higuchi_fd\n",
    "            sample_entropy_all = sample_entropy\n",
    "        else:\n",
    "            hjorth_activity_all = np.hstack((hjorth_activity_all, hjorth_activity))\n",
    "            hjorth_mobility_all = np.hstack((hjorth_mobility_all, hjorth_mobility))\n",
    "            hjorth_complexity_all = np.hstack((hjorth_complexity_all, hjorth_complexity))\n",
    "            higuchi_fd_all = np.hstack((higuchi_fd_all, higuchi_fd))\n",
    "            sample_entropy_all = np.hstack((sample_entropy_all, sample_entropy))\n",
    "    \n",
    "    # concatenate all features into a single matrix and convert to dataframe\n",
    "    all_eeg_features = np.hstack((band_power_all, hjorth_activity_all, hjorth_mobility_all,\n",
    "                                  hjorth_complexity_all, higuchi_fd_all, sample_entropy_all)) \n",
    "    all_eeg_features_df = pd.DataFrame(all_eeg_features, index=event_recognized_df.index, columns=all_features)\n",
    "\n",
    "    return all_eeg_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import autoreject\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from mne_features.univariate import compute_hjorth_mobility,compute_pow_freq_bands\n",
    "from mne.preprocessing import corrmap\n",
    "from eeglib.features import (bandPower, hjorthActivity, hjorthMobility,\n",
    "                             hjorthComplexity, sampEn, LZC, DFA, _HFD, HFD, PFD,\n",
    "                             synchronizationLikelihood)\n",
    "\n",
    "\n",
    "def process_session_eeg_mod(rns_data, event_df, event_column='spoken_difficulty_encoded', eeg_channel='BioSemi',\n",
    "                        eeg_montage='biosemi64', save_path='../output/', sbj_session = None, save_raw_eeg = False,\n",
    "                        run_autoreject=True, autoreject_epochs=20, run_ica=True, template_ica = None, average_reference=True,\n",
    "                        downsampling = True, n_decim = 16, low_cut=1, hi_cut=55, plot_epochs=False, bands_limits=None, \n",
    "                        analyze_pre_ica = False, eye_movement_removal=True, tmin=-.2, tmax=3, baseline=(None, 0),\n",
    "                        normalize_pow_freq=True, filter_events=True):\n",
    "\n",
    "    if bands_limits is None:\n",
    "        bands_limits = [4, 8, 15, 32, 55]\n",
    "    if filter_events:\n",
    "        event_detected = event_df[event_column].notnull()\n",
    "        event_recognized_df = event_df[event_detected]\n",
    "    else:\n",
    "        event_recognized_df = event_df\n",
    "\n",
    "    eeg_channel_names = mne.channels.make_standard_montage(eeg_montage).ch_names\n",
    "    df = pd.DataFrame(rns_data[eeg_channel][0], columns=rns_data[eeg_channel][1],\n",
    "                      index=rns_data[eeg_channel][2]['ChannelNames']).T\n",
    "    starting_time_s = rns_data[eeg_channel][1][0]\n",
    "    freq = rns_data[eeg_channel][2]['NominalSamplingRate']\n",
    "    rna_channel_names = list(df.columns)\n",
    "    rna_channel_names[1:65] = eeg_channel_names\n",
    "    info = mne.create_info(ch_names=rna_channel_names, ch_types=['stim'] + ['eeg'] * 64 + ['ecg'] * 2 + ['misc'] * 22,\n",
    "                           sfreq=freq)\n",
    "    info.set_montage(eeg_montage)\n",
    "\n",
    "    raw = mne.io.RawArray(df.T * 1e-6, info)\n",
    "    raw = raw.pick('eeg')\n",
    "    if average_reference:\n",
    "        raw = raw.set_eeg_reference(ref_channels='average')  # set average reference\n",
    "    if low_cut or hi_cut:\n",
    "        raw.filter(l_freq=low_cut, h_freq=hi_cut)\n",
    "    if downsampling:\n",
    "        raw.resample(freq/n_decim)\n",
    "        freq /= n_decim\n",
    "\n",
    "    trial_start_time = event_recognized_df.trial_start_time - starting_time_s  # reference for mne\n",
    "    event_values = event_recognized_df[event_column].values\n",
    "    events = np.column_stack((trial_start_time.values * freq,\n",
    "                              np.zeros(len(event_recognized_df), dtype=int),\n",
    "                              event_values)).astype(int)\n",
    "    event_dict = dict(easy=1, hard=2, unknown=0)\n",
    "    \n",
    "    # save raw data\n",
    "    if save_raw_eeg:\n",
    "        \n",
    "        raw_eeg_dir = '../output/saved_files/raw_eeg/'\n",
    "        if not os.path.isdir(raw_eeg_dir): os.makedirs(raw_eeg_dir)\n",
    "        raw.save(os.path.join(raw_eeg_dir, sbj_session+'_eeg_filt_raw.fif'), overwrite=True)\n",
    "\n",
    "    if run_ica:\n",
    "        \n",
    "        # create duplicate raw, event_df, event_recognized_df for pre and post ica comparison\n",
    "        if analyze_pre_ica:\n",
    "            raw_pre_ica = raw.copy()\n",
    "            event_df_pre_ica = event_df\n",
    "            event_recognized_df_pre_ica = event_recognized_df\n",
    "\n",
    "        # Fit ICA\n",
    "        ica = mne.preprocessing.ICA(n_components=64, random_state=64) # n_components as a decimal set % explained variance\n",
    "        ica.fit(raw)\n",
    "        \n",
    "        # Semi automatic artifact detection - Corrmap\n",
    "        if (sbj_session == 'sbj20ssn03') or (template_ica == None):\n",
    "            if eye_movement_removal:\n",
    "                eog_idx = [4, 5]\n",
    "            else:\n",
    "                eog_idx = [5]\n",
    "        else:\n",
    "            icas = [template_ica]+[ica]\n",
    "            corrmap(icas, template= (0,5), label = \"blink\", show=False)\n",
    "            \n",
    "            if eye_movement_removal:\n",
    "                corrmap(icas, template= (0,4), label = \"horizontal_eye_movement\", show=False)\n",
    "            identified_ica_label = [ica.labels_ for ica in icas]\n",
    "            \n",
    "            if eye_movement_removal:\n",
    "                eog_idx = identified_ica_label[1]['blink']+identified_ica_label[1]['horizontal_eye_movement']\n",
    "            else:\n",
    "                eog_idx = identified_ica_label[1]['blink']\n",
    "        \n",
    "        # Reconstruct filtered raw signal without Eye Components\n",
    "        ica.apply(raw, exclude=eog_idx)\n",
    "\n",
    "    else:\n",
    "        ica = None\n",
    "        eog_idx = None\n",
    "    \n",
    "    def process_session_eeg_inner(raw, event_recognized_df, event_df):\n",
    "    \n",
    "        epochs = mne.Epochs(raw, events, event_id=event_dict, tmin=tmin, tmax=tmax, baseline=baseline, preload=True, \n",
    "                                on_missing='warn')\n",
    "            \n",
    "        event_recognized_df = event_recognized_df[[e==() for e in epochs.drop_log]] # only keep good epochs in event_df\n",
    "        reject_log = None\n",
    "        \n",
    "        # EEG Feature Extraction - 24 features\n",
    "        extracted_24_features_df = eeg_features(epochs, event_recognized_df, bands_limits, eeg_channel_names, freq, normalize_pow_freq=normalize_pow_freq)\n",
    "\n",
    "        if len(epochs) < 10: # we need at least 10 epochs to run autoreject for cross validation\n",
    "            bad_epochs = pd.Series(np.full(len(event_df),np.NAN), index=event_df.index, name='autorejected')\n",
    "            event_df = event_df.join(bad_epochs)\n",
    "            reject_log = None\n",
    "        elif run_autoreject:\n",
    "            ar = autoreject.AutoReject(random_state=11,\n",
    "                                       n_jobs=1, verbose=False)\n",
    "            ar.fit(epochs[:autoreject_epochs])  # fit on a few epochs to save time\n",
    "            epochs_ar, reject_log = ar.transform(epochs, return_log=True)\n",
    "            bad_epochs = pd.Series(reject_log.bad_epochs, index=event_recognized_df.index, dtype=bool, name='autorejected')\n",
    "            event_df = event_df.join(bad_epochs)\n",
    "            epochs = epochs_ar\n",
    "            \n",
    "        return epochs, event_recognized_df, reject_log, event_df, extracted_24_features_df\n",
    "    \n",
    "    epochs, event_recognized_df, reject_log, event_df, extracted_24_features_df = process_session_eeg_inner(raw,\n",
    "                                                                                    event_recognized_df, event_df)\n",
    "        \n",
    "    try:\n",
    "        if plot_epochs:\n",
    "            if not os.path.isdir(save_path): os.makedirs(save_path)\n",
    "            ppid = event_recognized_df.iloc[0].ppid\n",
    "            session = event_recognized_df.iloc[0].session\n",
    "            block = event_recognized_df.iloc[0].block\n",
    "            trial = event_recognized_df.iloc[0].number_in_block\n",
    "\n",
    "            easy = epochs['easy'].average()\n",
    "            hard = epochs['hard'].average()\n",
    "            fig, axd = plt.subplot_mosaic([['left', 'left', 'right', 'right'],\n",
    "                                           ['lower left left', 'lower left right', 'lower right left',\n",
    "                                            'lower right right']],\n",
    "                                          figsize=(15, 12), constrained_layout=True)\n",
    "\n",
    "            easy.plot(spatial_colors=True, axes=axd['left'])\n",
    "            hard.plot(spatial_colors=True, axes=axd['right'])\n",
    "            epochs['easy'].plot_psd_topomap(bands=[(8, 12, 'Alpha'), (12, 30, 'Beta')], ch_type='eeg',\n",
    "                                            normalize=True,\n",
    "                                            axes=[axd['lower left left'], axd['lower left right']])\n",
    "            epochs['hard'].plot_psd_topomap(bands=[(8, 12, 'Alpha'), (12, 30, 'Beta')], ch_type='eeg',\n",
    "                                            normalize=True,\n",
    "                                            axes=[axd['lower right left'], axd['lower right right']])\n",
    "            axd['left'].title.set_text('Average (easy)')\n",
    "            axd['right'].title.set_text('Average (hard)')\n",
    "            axd['lower left left'].title.set_text('Alpha (8-12Hz)')\n",
    "            axd['lower left right'].title.set_text('Beta (12-30Hz) PSD (easy)')\n",
    "            axd['lower right left'].title.set_text('Alpha (8-12Hz)')\n",
    "            axd['lower right right'].title.set_text('Beta (12-30Hz) PSD (hard)')\n",
    "            plt.show()\n",
    "            fig.savefig(f\"{save_path}ppid_{ppid}_session_{session}_block_{block}_trial_{trial}_eeg.png\")\n",
    "            plt.close()\n",
    "            if reject_log:\n",
    "                result_fig = reject_log.plot('horizontal')\n",
    "                result_fig.savefig( \n",
    "                    f\"{save_path}ppid_{ppid}_session_{session}_block_{block}_trial_{trial}_eeg_autoreject_preica.png\")\n",
    "                plt.close()\n",
    "            ica.plot_components(show=False)\n",
    "            plt.savefig(f\"{save_path}ppid_{ppid}_session_{session}_block_{block}_trial_{trial}_eeg_ica.png\")\n",
    "            plt.close()\n",
    "    except Exception as e:\n",
    "        print('some plotting error', e)\n",
    "        pass\n",
    "    \n",
    "    event_df = event_df.join(extracted_24_features_df)\n",
    "    \n",
    "    if run_ica and analyze_pre_ica:\n",
    "        _, _, _, event_df_pre_ica, extracted_24_features_df_pre_ica = process_session_eeg_inner(raw_pre_ica, \n",
    "                                                                        event_recognized_df_pre_ica, event_df_pre_ica)\n",
    "        \n",
    "        event_df_pre_ica.columns = event_df_pre_ica.columns.str.replace(\"autorejected\", \"autorejected_raw\")\n",
    "        extracted_24_features_df_pre_ica = extracted_24_features_df_pre_ica.add_suffix(\"_raw\")\n",
    "\n",
    "        event_df = event_df.join(event_df_pre_ica['autorejected_raw'])\n",
    "        event_df = event_df.join(extracted_24_features_df_pre_ica)\n",
    "\n",
    "    return event_df, epochs, events, info, reject_log, ica, eog_idx\n",
    "\n",
    "def eeg_features(epochs, event_recognized_df, bands_limits, eeg_channel_names, fs, win_size = 1024, normalize_pow_freq=True):\n",
    "    \n",
    "    # identify available frequency bands\n",
    "    bands = np.asarray(bands_limits)\n",
    "    band_intervals = list(zip(bands[:-1], bands[1:]))\n",
    "    \n",
    "    #initiate empty matrix for all features\n",
    "    band_power_all = np.empty([len(epochs), len(eeg_channel_names)*len(band_intervals)])\n",
    "    hjorth_activity = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    hjorth_mobility = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    hjorth_complexity = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    higuchi_fd = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    sample_entropy = np.empty([len(epochs), len(eeg_channel_names)])\n",
    "    \n",
    "    # create column list for dataframe (band power column arrangement will be different than others due to its function)\n",
    "    channel_band_power = [f\"{chan_name}_{each_band[0]}-{each_band[1]}_Hz_Power\"\n",
    "                              for chan_name in eeg_channel_names\n",
    "                                  for each_band in band_intervals]\n",
    "    band_specific_features_list = ['Hjorth_Activity', 'Hjorth_Mobility', 'Hjorth_Complexity', \n",
    "                                   'Higuchi_FD', 'Sample_entropy']\n",
    "    band_specific_features = [f\"{chan_name}_{each_band[0]}-{each_band[1]}_Hz_{each_feature}\"\n",
    "                          for each_feature in band_specific_features_list\n",
    "                              for each_band in band_intervals\n",
    "                                  for chan_name in eeg_channel_names]\n",
    "    # combine column name for all features\n",
    "    all_features = channel_band_power + band_specific_features\n",
    "\n",
    "    # band power calculation\n",
    "    for i in range(len(epochs)):\n",
    "        eeg_data = np.squeeze(epochs.get_data(item=i))\n",
    "        band_power = compute_pow_freq_bands(sfreq=fs, data=eeg_data, freq_bands=bands, normalize=normalize_pow_freq,\n",
    "                                            psd_params={'welch_n_fft': win_size, 'welch_n_per_seg': win_size})\n",
    "        band_power_all[i, :] = band_power\n",
    "    \n",
    "    # Other features calculation\n",
    "    for index, freq_band in enumerate(band_intervals):\n",
    "        band_specific_epoch = np.squeeze(epochs.filter(freq_band[0],freq_band[1], verbose = False).get_data())\n",
    "        for i in range(len(epochs.events)):\n",
    "            for ii in range(64):\n",
    "                # band-specific Hjorth activity, mobility and complexity\n",
    "                hjorth_activity[i,ii] = hjorthActivity(band_specific_epoch[i][ii])\n",
    "                hjorth_mobility[i,ii] = hjorthMobility(band_specific_epoch[i][ii])\n",
    "                hjorth_complexity[i,ii] = hjorthComplexity(band_specific_epoch[i][ii])\n",
    "\n",
    "                # band-specific HFD\n",
    "                higuchi_fd[i,ii] = HFD(band_specific_epoch[i][ii])\n",
    "\n",
    "                # band-specific sample entropy\n",
    "                sample_entropy[i,ii] = sampEn(band_specific_epoch[i][ii])\n",
    "    # concatenate each band specific features into a single matrix \n",
    "        if index == 0:\n",
    "            hjorth_activity_all = hjorth_activity\n",
    "            hjorth_mobility_all = hjorth_mobility\n",
    "            hjorth_complexity_all = hjorth_complexity\n",
    "            higuchi_fd_all = higuchi_fd\n",
    "            sample_entropy_all = sample_entropy\n",
    "        else:\n",
    "            hjorth_activity_all = np.hstack((hjorth_activity_all, hjorth_activity))\n",
    "            hjorth_mobility_all = np.hstack((hjorth_mobility_all, hjorth_mobility))\n",
    "            hjorth_complexity_all = np.hstack((hjorth_complexity_all, hjorth_complexity))\n",
    "            higuchi_fd_all = np.hstack((higuchi_fd_all, higuchi_fd))\n",
    "            sample_entropy_all = np.hstack((sample_entropy_all, sample_entropy))\n",
    "    \n",
    "    # concatenate all features into a single matrix and convert to dataframe\n",
    "    all_eeg_features = np.hstack((band_power_all, hjorth_activity_all, hjorth_mobility_all,\n",
    "                                  hjorth_complexity_all, higuchi_fd_all, sample_entropy_all)) \n",
    "    all_eeg_features_df = pd.DataFrame(all_eeg_features, index=event_recognized_df.index, columns=all_features)\n",
    "\n",
    "    return all_eeg_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "mna",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "mna",
   "language": "python",
   "name": "mna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
