{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96671aa",
   "metadata": {},
   "source": [
    "# Analyze sessions in batch from Phase 1 of AdaDrive (work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261d0746",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# setting path\n",
    "sys.path.append('..')\n",
    "import mne\n",
    "import matplotlib\n",
    "from mna.utils.rnapp_data_format import read_all_lslpresets, return_metadata_from_name, event_data_from_data\n",
    "import pickle, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from scipy.io import savemat\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from mna.utils.rnapp_data_format import read_all_lslpresets, return_metadata_from_name, event_data_from_data\n",
    "import pickle\n",
    "from statannotations.Annotator import Annotator\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "import mne\n",
    "import glob \n",
    "import random\n",
    "import re\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels as sm\n",
    "from scipy.stats import spearmanr\n",
    "# matplotlib.use('Qt5Agg')\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "from mna.utils.rnapp_data_format import read_all_files\n",
    "# 1. Read a RN App, converted pkl file, and create the metadata and data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c13166b",
   "metadata": {},
   "source": [
    "# Aux functions, read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa8d3fc-4b04-4d3a-ad36-8179b5eac0c8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop over the list of csv files\n",
    "def read_motor_csvs():\n",
    "    csv_files = glob.glob(os.path.join(output_dir, \"ppid*_motor.csv\"))\n",
    "    all_dfs = None\n",
    "    for f in csv_files:\n",
    "        # read the csv file\n",
    "        if not type(all_dfs)==pd.core.frame.DataFrame:\n",
    "            all_dfs = pd.read_csv(f)\n",
    "        else:\n",
    "            all_dfs = pd.concat([all_dfs, pd.read_csv(f)], ignore_index=True)\n",
    "    all_dfs = all_dfs[all_dfs.columns.drop(list(all_dfs.filter(regex='Unnamed')))]\n",
    "    return all_dfs\n",
    "\n",
    "def get_motor_epochs():\n",
    "    epochs_files = glob.glob(os.path.join(output_dir, \"**/*ica_epochs.pickle\"), recursive=True)\n",
    "    motor_epochs = []\n",
    "    for each_file in epochs_files:\n",
    "        motor_epochs.append(pickle.load(open(each_file, 'rb')))\n",
    "    motor_epochs = mne.concatenate_epochs(motor_epochs)\n",
    "    for col in ['ppid','session','block','number_in_block','trial']:\n",
    "        motor_epochs.metadata[col] = motor_epochs.metadata[col].astype(int)\n",
    "    return motor_epochs\n",
    "\n",
    "def get_motor_intensity_info(input_df):\n",
    "    \n",
    "    def str_list_to_list(lst):\n",
    "        str_single_space = re.sub(\"\\s+\", \" \", lst.strip())\n",
    "        str_no_brackets = re.sub(\"[\\[\\]]\", \"\", lst)\n",
    "        return [float(n) for n in str_no_brackets.split()]\n",
    "    \n",
    "    try:\n",
    "        all_steer_events = input_df['post_steer_event_raw']\n",
    "        all_steer_events_finalized = all_steer_events.apply(str_list_to_list)\n",
    "    except:\n",
    "        all_steer_events_finalized = input_df['post_steer_event_raw']\n",
    "    norm_pos = lambda wheel_pos: np.asarray(wheel_pos)/np.asarray(wheel_pos[0])\n",
    "    final_pos = lambda final_wheel_pos: np.asarray(final_wheel_pos[-1])-np.asarray(final_wheel_pos[0])\n",
    "\n",
    "    norm_pos_df = all_steer_events_finalized.apply(norm_pos)\n",
    "    final_pos_df = abs(all_steer_events_finalized.apply(final_pos))\n",
    "    input_df[\"Steer_Wheel_Degree\"] = abs(all_steer_events_finalized.apply(final_pos))\n",
    "    all_dfs = []\n",
    "    for sub in input_df.ppid.unique():\n",
    "        sub_df = input_df[input_df.ppid==sub]\n",
    "        sub_df[\"Steer_Wheel_Degree_Categorical\"] = pd.qcut(sub_df.Steer_Wheel_Degree, 2, labels=[\"Low\", \"High\"]) #2=High, 1 =Low\n",
    "        sub_df[\"Steer_Wheel_Degree_Encoded\"] = sub_df.Steer_Wheel_Degree_Categorical.replace({'High': 2, 'Low': 1})\n",
    "        all_dfs.append(sub_df)\n",
    "    return pd.concat(all_dfs).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def str_list_to_list(lst):\n",
    "    str_single_space = re.sub(\"\\s+\", \" \", lst.strip())\n",
    "    str_no_brackets = re.sub(\"[\\[\\]]\", \"\", lst)\n",
    "    return [float(n) for n in str_no_brackets.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4608af72-c0ae-443f-9e53-b6cea0773f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 77 columns\n",
      "6905 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/86xrfhcs2bl42hc35fbdmqz40000gn/T/ipykernel_9131/127439797.py:19: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  motor_epochs = mne.concatenate_epochs(motor_epochs)\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../output/batch_analysis_non_baseline_non_averaged/'\n",
    "remove_sessions = [(15,1),(22,1)]\n",
    "rel_regions = {'premotor_regions': ['FC3', 'FC1', 'FCz', 'FC2', 'FC4'], 'dorsolateral_prefrontal': ['AF3', 'AFz', 'AF4'], 'intermediate_frontal': ['F3', 'F1', 'Fz', 'F2', 'F4']}\n",
    "all_regions = sum(rel_regions.values(),[])\n",
    "\n",
    "pupil_df = pd.read_csv(f\"../output/pupil_exposure/participant_level_exposure_fits.csv\")\n",
    "trial_dfs = pd.read_csv(f\"{output_dir}all_results.csv\")\n",
    "motor_dfs = read_motor_csvs()\n",
    "motor_dfs['post_steer_event_raw'] = motor_dfs['post_steer_event_raw'].apply(str_list_to_list)\n",
    "motor_epochs = get_motor_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36208051",
   "metadata": {},
   "source": [
    "# Clean up dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a9aafc-5532-4331-94fc-d568a049d0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n",
      "Replacing existing metadata with 79 columns\n"
     ]
    }
   ],
   "source": [
    "# seaborn\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_palette(\"tab10\")\n",
    "from mna.utils.batch_feature_extraction import clean_up_adadrive_trials\n",
    "\n",
    "motor_outlier_cols = ['abs_sum_delta_steer_input']\n",
    "cols_to_outlier_detect = ['bpm', 'sdnn', 'rmssd', 'pnn50']\n",
    "experimental_cols = ['spoken_difficulty', 'trial_duration', 'density', 'trial_damage']\n",
    "eye_cols = ['Left Pupil Diameter', \"NSLR_count_Fixation\", \"NSLR_count_Saccade\",\n",
    "            'NSLR_mean_duration_Fixation', 'NSLR_mean_duration_Saccade',\n",
    "            'NSLR_first_onset_Fixation', 'NSLR_first_onset_Saccade']\n",
    "ecg_cols = ['bpm', 'sdnn', 'rmssd', 'pnn50']  # rmssd = parasympathetic\n",
    "motor_cols = ['abs_sum_delta_steer_input', 'abs_sum_delta_brake_input', 'abs_sum_delta_throttle_input']\n",
    "\n",
    "\n",
    "def clean_up_trials(input_df):\n",
    "    all_dfs_final = clean_up_adadrive_trials(input_df.copy())\n",
    "    # damage change\n",
    "    all_dfs_final = all_dfs_final.sort_values(by=['ppid', 'session', 'block', 'trial'])\n",
    "    # nan, outliers\n",
    "    #for col in motor_outlier_cols:\n",
    "    #    all_dfs_final[col] = all_dfs_final[col].mask(all_dfs_final[col].sub(all_dfs_final[col].mean()).div(all_dfs_final[col].std()).abs().gt(2))\n",
    "    #all_dfs_final['abs_sum_delta_brake_input'] = all_dfs_final['abs_sum_delta_brake_input'].mask(all_dfs_final['abs_sum_delta_brake_input']>.1)\n",
    "\n",
    "    all_dfs_final['NSLR_first_onset_Fixation'] = all_dfs_final['NSLR_first_onset_Fixation'] - all_dfs_final[\n",
    "        'trial_start_time']\n",
    "    all_dfs_final['NSLR_first_onset_Saccade'] = all_dfs_final['NSLR_first_onset_Saccade'] - all_dfs_final[\n",
    "        'trial_start_time']\n",
    "\n",
    "    all_dfs_final[\n",
    "        'throttle_over_brake'] = all_dfs_final.abs_sum_delta_throttle_input / all_dfs_final.abs_sum_delta_brake_input\n",
    "    return all_dfs_final\n",
    "\n",
    "\n",
    "trial_dfs = clean_up_trials(trial_dfs)\n",
    "trial_dfs = trial_dfs.loc[~trial_dfs.ppid_session.isin([f\"{es[0]}_{es[1]}\" for es in remove_sessions])]\n",
    "motor_dfs = clean_up_trials(motor_dfs)\n",
    "\n",
    "# luminance effect removal from pupil diameter\n",
    "trial_dfs['Raw Left Pupil Diameter'] = trial_dfs['Left Pupil Diameter']\n",
    "motor_dfs['Raw Left Pupil Diameter'] = motor_dfs['Left Pupil Diameter']\n",
    "p_val_criteria = 0.05\n",
    "for index, row in trial_dfs.reset_index(drop=True).iloc[1:].iterrows():\n",
    "    last_ppid = trial_dfs.iloc[index - 1].ppid\n",
    "    last_session = trial_dfs.iloc[index - 1].session\n",
    "    last_trial = trial_dfs.iloc[index - 1].trial\n",
    "    last_opacity = trial_dfs.iloc[index - 1].density\n",
    "    if ((row.ppid == last_ppid) & (row.session == last_session) & (row.trial == last_trial + 1)):  # if continuous\n",
    "        # if there is a significant effect of opacity on pupil\n",
    "        if pupil_df.loc[pupil_df['sub'] == last_ppid, 'p_opacities'].values < p_val_criteria:\n",
    "            this_opacity = row.density\n",
    "            this_pupil_diameter = row['Left Pupil Diameter']\n",
    "            weight = pupil_df.loc[pupil_df['sub'] == last_ppid, 'w_opacities']\n",
    "            adjustment = (this_opacity - last_opacity) * weight\n",
    "            trial_dfs.iloc[index, trial_dfs.columns.get_loc('Left Pupil Diameter')] -= adjustment\n",
    "            motor_dfs.loc[(motor_dfs.ppid == last_ppid) & (motor_dfs.session == last_session) & (\n",
    "                        motor_dfs.trial == last_trial + 1), 'Left Pupil Diameter'] -= adjustment  # update motor df too\n",
    "            motor_epochs.metadata.loc[(motor_epochs.metadata.ppid == last_ppid) &\n",
    "                                      (motor_epochs.metadata.session == last_session) &\n",
    "                                      (\n",
    "                                                  motor_epochs.metadata.trial == last_trial + 1), 'Left Pupil Diameter'] += adjustment  # update motor epochs too\n",
    "# pupil bins\n",
    "motor_dfs['pupil_bin'] = motor_dfs.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=['low', 'high']))\n",
    "trial_dfs['pupil_bin'] = trial_dfs.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=['low', 'high']))\n",
    "motor_epochs.metadata['pupil_bin'] = motor_epochs.metadata.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=['low', 'high']))\n",
    "motor_dfs['pupil_bin_encoded'] = motor_dfs.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=[0, 1]))\n",
    "trial_dfs['pupil_bin_encoded'] = trial_dfs.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=[0, 1]))\n",
    "motor_epochs.metadata['pupil_bin_encoded'] = motor_epochs.metadata.groupby(['ppid'])['Left Pupil Diameter'].transform(\n",
    "    lambda x: pd.qcut(x, 2, labels=[0, 1]))\n",
    "preturn = 1000\n",
    "motor_epochs.apply_baseline((-(preturn / 1000), -((preturn - 250) / 1000)))\n",
    "\n",
    "# participant-level binning of motor data, replaces the session-level info already there\n",
    "motor_dfs = get_motor_intensity_info(motor_dfs)\n",
    "motor_epochs.metadata = get_motor_intensity_info(motor_epochs.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export to MATLAB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "lsl_dir = \"../mna/LSLPresets/\"\n",
    "vid_dir = '../data/videos/'\n",
    "output_path = '../output/matlab_exports/'\n",
    "Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "onlyfiles = [f for f in listdir(data_dir) if isfile(join(data_dir, f)) and '.pkl' in f]\n",
    "file_to_sess = {f: (int(f.rsplit('Sbj_',1)[1].split('-')[0]),int(f.rsplit('Ssn_',1)[1].split('.')[0])) for f in onlyfiles}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path ../data/09_24_2022_11_31_56-Exp_adadrive-Sbj_18-Ssn_3.dats.pkl\n"
     ]
    }
   ],
   "source": [
    "selected_file = onlyfiles[0]\n",
    "selected_pp_sess = file_to_sess[selected_file]\n",
    "input_path = data_dir + selected_file # pick a random file, idx 26 and\n",
    "\n",
    "print(f\"input_path {input_path}\")\n",
    "metadata_jsons = read_all_lslpresets(path_to_jsonfiles=lsl_dir)\n",
    "with open(input_path, 'rb') as handle:\n",
    "    rns_data = pickle.load(handle)\n",
    "\n",
    "for key in rns_data.keys():\n",
    "    rns_data[key].append(return_metadata_from_name(key, metadata_jsons))\n",
    "\n",
    "eeg_channel_names = mne.channels.make_standard_montage('biosemi64').ch_names\n",
    "eeg_df = pd.DataFrame(rns_data['BioSemi'][0], columns=rns_data['BioSemi'][1],\n",
    "                  index=rns_data['BioSemi'][2]['ChannelNames']).T\n",
    "eeg_df = eeg_df.iloc[:,1:65]\n",
    "eeg_df.columns = eeg_channel_names\n",
    "\n",
    "motor_df = pd.DataFrame(rns_data['Unity_MotorInput'][0], columns=rns_data['Unity_MotorInput'][1],\n",
    "                          index=rns_data['Unity_MotorInput'][2]['ChannelNames']).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "all_eeg_trials = []\n",
    "all_motor_trials = []\n",
    "sub_trials = trial_dfs[(trial_dfs.ppid == selected_pp_sess[0]) & (trial_dfs.session == selected_pp_sess[1])]\n",
    "max_eeg_trial = int(sub_trials.trial_duration.min()*2048) # ensure same size\n",
    "max_motor_trial = int(sub_trials.trial_duration.min()*40) # ensure same size\n",
    "\n",
    "new_sample_rate = 100\n",
    "for index,trial in sub_trials.iterrows():\n",
    "    #sub_eeg_df = eeg_df[(eeg_df.index >= trial.trial_start_time) & (eeg_df.index <= trial.trial_end_time)].iloc[:max_eeg_trial]\n",
    "    #sub_motor_df = motor_df[(motor_df.index >= trial.trial_start_time) & (motor_df.index <= trial.trial_end_time)].iloc[:max_motor_trial]\n",
    "    sub_eeg_df = eeg_df[(eeg_df.index >= trial.trial_start_time) & (eeg_df.index <= trial.trial_end_time)]\n",
    "    sub_motor_df = motor_df[(motor_df.index >= trial.trial_start_time) & (motor_df.index <= trial.trial_end_time)]\n",
    "\n",
    "    # eeg resample\n",
    "    secs = sub_eeg_df.shape[0]/2048 # Number of seconds in signal X\n",
    "    samps = int(secs*new_sample_rate)     # Number of samples to downsample\n",
    "    sub_eeg_df = scipy.signal.resample(sub_eeg_df, samps)\n",
    "\n",
    "    # motor resample\n",
    "    secs = sub_motor_df.shape[0]/40 # Number of seconds in signal X\n",
    "    samps = int(secs*new_sample_rate)     # Number of samples to downsample\n",
    "    sub_motor_df = scipy.signal.resample(sub_motor_df, samps)\n",
    "\n",
    "    all_eeg_trials.append(sub_eeg_df)\n",
    "    all_motor_trials.append(sub_motor_df)\n",
    "#all_eeg_trials = np.array(all_eeg_trials)\n",
    "#all_motor_trials = np.array(all_motor_trials)\n",
    "all_eeg_trials_cat = np.concatenate(all_eeg_trials).T\n",
    "all_motor_trials_cat = np.concatenate(all_motor_trials).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "mdic = {\"eeg\": all_eeg_trials, \"motor\": all_motor_trials, \"label\": f\"{trial.ppid}_{trial.session}\", \"sample_rate\": new_sample_rate}\n",
    "savemat(f\"{output_path}{trial.ppid}_{trial.session}.mat\", mdic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-28552.11897898, -28568.03138624, -28538.09691621, ...,\n        -29673.08280386, -29640.89760013, -29671.4593658 ],\n       [-30849.58537421, -30836.43232117, -30826.29087197, ...,\n        -32900.2297785 , -32874.96724528, -32875.70944564],\n       [ -4415.75010314,  -4350.4570849 ,  -4378.53117744, ...,\n        -10148.60620601, -10127.5791655 , -10131.15583926],\n       ...,\n       [-19380.8512941 , -19322.95840799, -19339.67256114, ...,\n        -22131.57051793, -22109.4102402 , -22126.96601199],\n       [-12233.20386159, -12210.70363604, -12215.99188763, ...,\n        -10307.06067477, -10299.10520069, -10309.77446623],\n       [-14985.12440857, -14928.26469337, -14941.61101949, ...,\n        -16630.7690051 , -16599.53869508, -16626.49498982]])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_eeg_trials_cat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_eeg_trials"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "mna",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
